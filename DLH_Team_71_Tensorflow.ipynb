{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZKingQ/CS598-DLH-SP24/blob/main/DLH_Team_71_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS598 Deep Learning for Healthcare - Final Project - DeepMicro: Deep Representation Learning for Disease Prediction based on Microbiome Data\n",
        "\n",
        "### Lotte Zhu, Kaiqing Zhang, Matthew Trueblood (Team ID: 71)\n",
        "#### GitHub Link: https://github.com/ZKingQ/CS598-DLH-SP24"
      ],
      "metadata": {
        "id": "nfyi6FdlRDyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before you use this template\n",
        "\n",
        "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Notebook to Google Drive\n",
        "Upload the data, pretrianed model, figures, etc to your Google Drive, then mount this notebook to Google Drive. After that, you can access the resources freely.\n",
        "\n",
        "Instruction: https://colab.research.google.com/notebooks/io.ipynb\n",
        "\n",
        "Example: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
        "\n",
        "Video: https://www.youtube.com/watch?v=zc8g8lGcwQU"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although here we mount the My Google Drive to the Colab, we will update the GitHub repository code later to load the data from the public cloud directly. This is to ensure the reproducibility of the project."
      ],
      "metadata": {
        "id": "qKiBIcArvMMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5gL7PJw2sGb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efefc6cf-4bf9-4e81-f721-7c24d0252c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "<!-- This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
        "\n",
        "*   Background of the problem\n",
        "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
        "  * what is the importance/meaning of solving the problem\n",
        "  * what is the difficulty of the problem\n",
        "  * the state of the art methods and effectiveness.\n",
        "*   Paper explanation\n",
        "  * what did the paper propose\n",
        "  * what is the innovations of the method\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem). -->\n",
        "\n",
        "\n",
        "The expanding knowledge of microbiota uncovers its crucial role in human health [1]. It plays an important role in immune system, metabolism functions and even carcinognesis of certain cancers, hence microbiota can be used to predict various disease with emerging sequencing technologies [1,2,3,4,5,6]. However, there are three major challenges to realize the predictions in practice [7]. First, the low number of samples, together with the large number of features, leads to the curse of dimensionality. Second, there is a research gap in using strain-level profiles to classify samples into patient and healthy control groups across different diseases. Third, a rigorous validation framework is essential. Prior research has shown that tuning hyperparameters on the test set without a separate validation set may lead to an overestimation of model performance [8,9,10].\n",
        "\n",
        "The DeepMicro paper proposes the deployment of autoencoders to learn low-dimensional representations from microbiota data and then predict disease by another classification model based on the learned representations, with both trainings having thorough validation schemes [7]. The authors hypothesize that these innovations can contribute to the followings:\n",
        "\n",
        "1. The appropriate autoencoders can effectively solve the curse of dimensionality.\n",
        "\n",
        "2. They also reduce latency compared with alternative models without representation learing, in the mean time maintaining favorable training metrics.\n",
        "\n",
        "In this project, our primary objective revolves around the implementation and evaluation of various autoencoder architectures. We aim to validate the disease prediction capabilities as outlined in the paper. Furthermore, we discuss the ablations inherent in the innovation of autoencoder. The rationale for choosing this paper stems from our pursuit of knowledge in deep representation learning.\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "<!-- List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "\n",
        "\n",
        "1.   Hypothesis 1: xxxxxxx\n",
        "2.   Hypothesis 2: xxxxxxx\n",
        "\n",
        "You can insert images in this notebook text, [see this link](https://stackoverflow.com/questions/50670920/how-to-insert-an-inline-image-in-google-colaboratory-from-google-drive) and example below:\n",
        "\n",
        "![sample_image.png](https://drive.google.com/uc?export=view&id=1g2efvsRJDxTxKz-OY3loMhihrEUdBxbc)\n",
        "\n",
        "\n",
        "You can also use code to display images, see the code below.\n",
        "\n",
        "The images must be saved in Google Drive first.\n",
        "\n",
        "-->\n",
        "\n",
        "Our team achieved successful replication of the model by leveraging its open source codebase, resulting in metrics that are comparable to those showcased in the DeepMicro paper. In our endeavor, we thoroughly examined and addressed the claims below put forth in the original paper.\n",
        "\n",
        "1. **Dimensionality reduction engineering with traditional statistical techniques including Principal Component Analysis (PCA) and Gaussian Random Projection (GRP)**\n",
        "\n",
        "- Principal Component Analysis (PCA) aims to capture the most significant patterns and variations in a dataset by identifying orthogonal axes, known as principal components, that maximize the data variance.\n",
        "- Gaussian Random Projection (GRP) seeks to preserve pairwise distances between data points by projecting them onto a lower-dimensional space using random projections drawn from a Gaussian distribution.\n",
        "\n",
        "2. **Innovated representation learning employing with four different autoencoders including Shallow Autoencoder (SAE), Deep Autoencoder (DAE), Variational Autoencoder (VAE), and Convolutional Autoencoder (CAE)**\n",
        "\n",
        "- Shallow Autoencoder (SAE): This is the simplest form of an autoencoder, consisting of a fully\n",
        "connected encoder layer and a decoder layer. The latent representation is obtained from the encoder\n",
        "layer, which is a lower-dimensional space compared to the original input.\n",
        "- Deep Autoencoder (DAE): In addition to the encoder and decoder layers, DAE introduces hidden\n",
        "layers between the input and latent layers and between the latent and output layers. Rectified Linear\n",
        "Unit (ReLU) activation functions are used in the hidden layers.\n",
        "- Variational Autoencoder (VAE): VAE learns probabilistic representations by approximating the\n",
        "true posterior distribution of latent embeddings. It assumes that the posterior distribution follows\n",
        "a Gaussian distribution. VAE uses an encoder network to encode the means and variances of the\n",
        "Gaussian distribution and samples the latent representation from this distribution. The decoder\n",
        "network then reconstructs the input based on the sampled latent representation.\n",
        "- Convolutional Autoencoder (CAE): Instead of fully connected layers, CAE incorporates convo-\n",
        "lutional layers, where each unit is connected to local regions of the previous layer. Convolutional layers use filters (kernels) to perform convolution operations. CAE employs convolutional transpose layers (deconvolutional layers) to make the decoder symmetric to the encoder. No pooling layers\n",
        "are used in CAE.\n",
        "\n",
        "3. **Classification learning including including Support Vector Machine (SVM), Random Forest (RF), and Multi-Layer Perceptron (MLP)**\n",
        "- Support Vector Machine (SVM) is a supervised learning algorithm that aims to find an optimal hyperplane to classify data by maximizing the margin between different classes.\n",
        "- Random Forest (RF) is an ensemble learning method that constructs a multitude of decision trees and combines their predictions to make classifications.\n",
        "- Multi-Layer Perceptron (MLP) is a type of neural network that consists of multiple layers of interconnected nodes, enabling it to learn non-linear relationships and perform classification tasks.\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Set Up and Packages Import"
      ],
      "metadata": {
        "id": "zPov0WCKWbPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python version\n",
        "!python --version"
      ],
      "metadata": {
        "id": "oTXyVLh8YFl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d84f7d-1721-4eba-ac48-d1fa00baf6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up tensorflow env\n",
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow==2.12.0\n",
        "# !pip install keras==2.12.0\n",
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "WMEQdI728g55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbaab4ff-ec43-4651-d947-040c53bd816a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras>=3.2.0 (from scikeras)\n",
            "  Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->scikeras)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Collecting optree (from keras>=3.2.0->scikeras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Installing collected packages: namex, optree, scikit-learn, keras, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.2.1 namex-0.0.7 optree-0.11.0 scikeras-0.13.0 scikit-learn-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages needed in this project\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import datetime\n",
        "import math\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# importing keras\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.layers import Dense, Dropout, Input, Lambda, Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, Flatten, Reshape, Cropping2D\n",
        "from keras import backend as K\n",
        "from keras.losses import MeanSquaredError as mse, binary_crossentropy, MeanSquaredError, BinaryCrossentropy\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Lyf5Jfp7sGWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Path"
      ],
      "metadata": {
        "id": "XrtmVFrvcW6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We downloaded two datasets, abundance and marker from the [DeepMicro codebase](https://github.com/minoh0201/DeepMicro/tree/master/data). They are stored in the following path on Google Drive:"
      ],
      "metadata": {
        "id": "SRRY_dsgYL2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data dir\n",
        "raw_data_dir = '/content/drive/My Drive/Colab Notebooks/data/'"
      ],
      "metadata": {
        "id": "yGCbNWqfcRcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Description\n",
        "\n",
        "Our reproductivity utilizes the same datasets as the original paper, which include six disease (Table 1). They are inflammatory bowel disease (IBD), type 2 diabetes in European women (EW-T2D), type 2 diabetes in Chinese (C-T2D), obesity (Obesity), liver cirrhosis (Cirrhosis), and colorectal cancer (Colorectal).\n",
        "![](assets/Data_Table1.png)\n",
        "\n",
        "In each dataset, marker profile and abundance profile of microbiome are used to train our models (Table 2).\n",
        "![](assets/Data_Table2.png)\n",
        "\n",
        "All the data are stored in txt format and the data path structure is as following.\n",
        "```\n",
        ".\n",
        "├── ...\n",
        "├── data                              # Data folder\n",
        "│   ├── marker                        # Marker profile data\n",
        "│       ├── marker_IBD.txt            # Inflammatory bowel disease (IBD)\n",
        "│       ├── marker_WT2D.txt           # Type 2 diabetes in European women (EW-T2D)\n",
        "│       ├── marker_T2D.txt            # Type 2 diabetes in Chinese (C-T2D)\n",
        "│       ├── marker_Obesity.txt        # Obesity (Obesity)\n",
        "│       ├── marker_Cirrhosis.txt      # Liver cirrhosis (Cirrhosis)\n",
        "│       ├── marker_Colorectal.txt     # Colorectal cancer (Colorectal)\n",
        "│   ├── abundance                     # Abundance profile data\n",
        "│       ├── abundance_IBD.txt         # Inflammatory bowel disease (IBD)\n",
        "│       ├── abundance_WT2D.txt        # Type 2 diabetes in European women (EW-T2D)\n",
        "│       ├── abundance_T2D.txt         # Type 2 diabetes in Chinese (C-T2D)\n",
        "│       ├── abundance_Obesity.txt     # Obesity (Obesity)\n",
        "│       ├── abundance_Cirrhosis.txt   # Liver cirrhosis (Cirrhosis)\n",
        "│       ├── abundance_Colorectal.txt  # Colorectal cancer (Colorectal)\n",
        "└── ...\n",
        "```\n",
        "In each txt file, it has different number of features and data points as shown in Table 1 and Table 2 above. In the sample demonstration below. The colorectal cancer of microbiome abundance profile has 503 features (exluding those dummy labels) and 121 entries.\n",
        "\n"
      ],
      "metadata": {
        "id": "FJNbhZZ7cTjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract a sample data of colorectal cancer of microbiome abundance profile\n",
        "sample = pd.read_csv(os.path.join(raw_data_dir, \"abundance\", \"abundance_Colorectal.txt\"), sep='\\t', index_col=0, header=None)\n",
        "sample = sample.T\n",
        "sample.head(10)"
      ],
      "metadata": {
        "id": "BYGSgWXzjdeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "aa6069e5-aff6-40d3-9f45-5efe5410d81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                     dataset_name            sampleID subjectID bodysite  \\\n",
              "1   Zeller_fecal_colorectal_cancer  CCIS00146684ST-4-0    fr-726    stool   \n",
              "2   Zeller_fecal_colorectal_cancer  CCIS00281083ST-3-0    fr-060    stool   \n",
              "3   Zeller_fecal_colorectal_cancer  CCIS02124300ST-4-0    fr-568    stool   \n",
              "4   Zeller_fecal_colorectal_cancer  CCIS02379307ST-4-0    fr-828    stool   \n",
              "5   Zeller_fecal_colorectal_cancer  CCIS03473770ST-4-0    fr-192    stool   \n",
              "6   Zeller_fecal_colorectal_cancer  CCIS06260551ST-3-0    fr-200    stool   \n",
              "7   Zeller_fecal_colorectal_cancer  CCIS07539127ST-4-0    fr-460    stool   \n",
              "8   Zeller_fecal_colorectal_cancer  CCIS07648107ST-4-0    fr-053    stool   \n",
              "9   Zeller_fecal_colorectal_cancer  CCIS08668806ST-3-0    fr-214    stool   \n",
              "10  Zeller_fecal_colorectal_cancer  CCIS09568613ST-4-0    fr-400    stool   \n",
              "\n",
              "0         disease age  gender country sequencing_technology  pubmedid  ...  \\\n",
              "1               n  72  female  france              Illumina  25432777  ...   \n",
              "2               n  53    male  france              Illumina  25432777  ...   \n",
              "3               n  35    male  france              Illumina  25432777  ...   \n",
              "4          cancer  67    male  france              Illumina  25432777  ...   \n",
              "5               n  29    male  france              Illumina  25432777  ...   \n",
              "6          cancer  58    male  france              Illumina  25432777  ...   \n",
              "7               n  77  female  france              Illumina  25432777  ...   \n",
              "8               n  62  female  france              Illumina  25432777  ...   \n",
              "9   small_adenoma  63    male  france              Illumina  25432777  ...   \n",
              "10              n  67    male  france              Illumina  25432777  ...   \n",
              "\n",
              "0  k__Eukaryota|p__Ascomycota|c__Saccharomycetes|o__Saccharomycetales|f__Saccharomycetaceae|g__Eremothecium|s__Eremothecium_unclassified  \\\n",
              "1                                                   0                                                                                      \n",
              "2                                                   0                                                                                      \n",
              "3                                                   0                                                                                      \n",
              "4                                                   0                                                                                      \n",
              "5                                                   0                                                                                      \n",
              "6                                                   0                                                                                      \n",
              "7                                                   0                                                                                      \n",
              "8                                                   0                                                                                      \n",
              "9                                                   0                                                                                      \n",
              "10                                                  0                                                                                      \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_antri  \\\n",
              "1                                                   0                                                                    \n",
              "2                                                   0                                                                    \n",
              "3                                                   0                                                                    \n",
              "4                                                   0                                                                    \n",
              "5                                                   0                                                                    \n",
              "6                                                   0                                                                    \n",
              "7                                                   0                                                                    \n",
              "8                                                   0                                                                    \n",
              "9                                                   0                                                                    \n",
              "10                                                  0                                                                    \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Bacillales|f__Bacillaceae|g__Lysinibacillus|s__Lysinibacillus_fusiformis  \\\n",
              "1                                                   0                                                                 \n",
              "2                                                   0                                                                 \n",
              "3                                                   0                                                                 \n",
              "4                                                   0                                                                 \n",
              "5                                                   0                                                                 \n",
              "6                                             0.31121                                                                 \n",
              "7                                                   0                                                                 \n",
              "8                                                   0                                                                 \n",
              "9                                                   0                                                                 \n",
              "10                                                  0                                                                 \n",
              "\n",
              "0  k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobacterium|s__Methanobacterium_unclassified  \\\n",
              "1                                                   0                                                                                                 \n",
              "2                                                   0                                                                                                 \n",
              "3                                                   0                                                                                                 \n",
              "4                                                   0                                                                                                 \n",
              "5                                                   0                                                                                                 \n",
              "6                                                   0                                                                                                 \n",
              "7                                                   0                                                                                                 \n",
              "8                                                   0                                                                                                 \n",
              "9                                                   0                                                                                                 \n",
              "10                                                  0                                                                                                 \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Bacillales|f__Bacillaceae|g__Lysinibacillus|s__Lysinibacillus_boronitolerans  \\\n",
              "1                                                   0                                                                     \n",
              "2                                                   0                                                                     \n",
              "3                                                   0                                                                     \n",
              "4                                                   0                                                                     \n",
              "5                                                   0                                                                     \n",
              "6                                             0.03562                                                                     \n",
              "7                                                   0                                                                     \n",
              "8                                                   0                                                                     \n",
              "9                                                   0                                                                     \n",
              "10                                                  0                                                                     \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Bavariicoccus|s__Bavariicoccus_seileri  \\\n",
              "1                                                   0                                                                     \n",
              "2                                                   0                                                                     \n",
              "3                                                   0                                                                     \n",
              "4                                                   0                                                                     \n",
              "5                                                   0                                                                     \n",
              "6                                                   0                                                                     \n",
              "7                                                   0                                                                     \n",
              "8                                                   0                                                                     \n",
              "9                                                   0                                                                     \n",
              "10                                                  0                                                                     \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Enterococcus|s__Enterococcus_gilvus  \\\n",
              "1                                                   0                                                                  \n",
              "2                                                   0                                                                  \n",
              "3                                                   0                                                                  \n",
              "4                                                   0                                                                  \n",
              "5                                             0.03756                                                                  \n",
              "6                                                   0                                                                  \n",
              "7                                                   0                                                                  \n",
              "8                                                   0                                                                  \n",
              "9                                                   0                                                                  \n",
              "10                                                  0                                                                  \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_otakiensis  \\\n",
              "1                                                   0                                                                         \n",
              "2                                                   0                                                                         \n",
              "3                                                   0                                                                         \n",
              "4                                                   0                                                                         \n",
              "5                                                   0                                                                         \n",
              "6                                                   0                                                                         \n",
              "7                                                   0                                                                         \n",
              "8                                                   0                                                                         \n",
              "9                                                   0                                                                         \n",
              "10                                                  0                                                                         \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum|s__Desulfotomaculum_ruminis  \\\n",
              "1                                                   0                                                                           \n",
              "2                                                   0                                                                           \n",
              "3                                                   0                                                                           \n",
              "4                                                   0                                                                           \n",
              "5                                                   0                                                                           \n",
              "6                                                   0                                                                           \n",
              "7                                                   0                                                                           \n",
              "8                                                   0                                                                           \n",
              "9                                                   0                                                                           \n",
              "10                                                  0                                                                           \n",
              "\n",
              "0  k__Bacteria|p__Firmicutes|c__Negativicutes|o__Selenomonadales|f__Veillonellaceae|g__Megasphaera|s__Megasphaera_sp_BV3C16_1  \n",
              "1                                                   0                                                                          \n",
              "2                                                   0                                                                          \n",
              "3                                                   0                                                                          \n",
              "4                                                   0                                                                          \n",
              "5                                                   0                                                                          \n",
              "6                                                   0                                                                          \n",
              "7                                                   0                                                                          \n",
              "8                                                   0                                                                          \n",
              "9                                                   0                                                                          \n",
              "10                                                  0                                                                          \n",
              "\n",
              "[10 rows x 714 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e363c26c-bc47-4427-aba0-ebe10758af53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>sampleID</th>\n",
              "      <th>subjectID</th>\n",
              "      <th>bodysite</th>\n",
              "      <th>disease</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>country</th>\n",
              "      <th>sequencing_technology</th>\n",
              "      <th>pubmedid</th>\n",
              "      <th>...</th>\n",
              "      <th>k__Eukaryota|p__Ascomycota|c__Saccharomycetes|o__Saccharomycetales|f__Saccharomycetaceae|g__Eremothecium|s__Eremothecium_unclassified</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_antri</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Bacillales|f__Bacillaceae|g__Lysinibacillus|s__Lysinibacillus_fusiformis</th>\n",
              "      <th>k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobacterium|s__Methanobacterium_unclassified</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Bacillales|f__Bacillaceae|g__Lysinibacillus|s__Lysinibacillus_boronitolerans</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Bavariicoccus|s__Bavariicoccus_seileri</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Enterococcus|s__Enterococcus_gilvus</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_otakiensis</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum|s__Desulfotomaculum_ruminis</th>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Negativicutes|o__Selenomonadales|f__Veillonellaceae|g__Megasphaera|s__Megasphaera_sp_BV3C16_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS00146684ST-4-0</td>\n",
              "      <td>fr-726</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>72</td>\n",
              "      <td>female</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS00281083ST-3-0</td>\n",
              "      <td>fr-060</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>53</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS02124300ST-4-0</td>\n",
              "      <td>fr-568</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>35</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS02379307ST-4-0</td>\n",
              "      <td>fr-828</td>\n",
              "      <td>stool</td>\n",
              "      <td>cancer</td>\n",
              "      <td>67</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS03473770ST-4-0</td>\n",
              "      <td>fr-192</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>29</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.03756</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS06260551ST-3-0</td>\n",
              "      <td>fr-200</td>\n",
              "      <td>stool</td>\n",
              "      <td>cancer</td>\n",
              "      <td>58</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.31121</td>\n",
              "      <td>0</td>\n",
              "      <td>0.03562</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS07539127ST-4-0</td>\n",
              "      <td>fr-460</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>77</td>\n",
              "      <td>female</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS07648107ST-4-0</td>\n",
              "      <td>fr-053</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>62</td>\n",
              "      <td>female</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS08668806ST-3-0</td>\n",
              "      <td>fr-214</td>\n",
              "      <td>stool</td>\n",
              "      <td>small_adenoma</td>\n",
              "      <td>63</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>CCIS09568613ST-4-0</td>\n",
              "      <td>fr-400</td>\n",
              "      <td>stool</td>\n",
              "      <td>n</td>\n",
              "      <td>67</td>\n",
              "      <td>male</td>\n",
              "      <td>france</td>\n",
              "      <td>Illumina</td>\n",
              "      <td>25432777</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 714 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e363c26c-bc47-4427-aba0-ebe10758af53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e363c26c-bc47-4427-aba0-ebe10758af53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e363c26c-bc47-4427-aba0-ebe10758af53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e577cbfa-bbe2-49bc-ab8d-ff5ce0e8e8d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e577cbfa-bbe2-49bc-ab8d-ff5ce0e8e8d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e577cbfa-bbe2-49bc-ab8d-ff5ce0e8e8d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the features excluding patients information\n",
        "len([ _ for _ in sample.columns if '|' in _ ])"
      ],
      "metadata": {
        "id": "5EjqDkrWm0lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fc42ce-48fb-4d1f-db2d-06de950167ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "503"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the dimensions of the sameple dataset\n",
        "sample.shape"
      ],
      "metadata": {
        "id": "i93VorpFlPnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d419be8-65ed-47fa-c9a1-11b61902e702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 714)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Have a generate descrption of the sample dataset\n",
        "sample.describe().T"
      ],
      "metadata": {
        "id": "PPFi9QXolIoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "42f83aa0-138b-4e11-e43e-2d11416e112d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   count unique  \\\n",
              "0                                                                 \n",
              "dataset_name                                         121      1   \n",
              "sampleID                                             121    121   \n",
              "subjectID                                            121    121   \n",
              "bodysite                                             121      1   \n",
              "disease                                              121      3   \n",
              "...                                                  ...    ...   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   121      2   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   121      5   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   121      2   \n",
              "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   121      2   \n",
              "k__Bacteria|p__Firmicutes|c__Negativicutes|o__S...   121      2   \n",
              "\n",
              "                                                                               top  \\\n",
              "0                                                                                    \n",
              "dataset_name                                        Zeller_fecal_colorectal_cancer   \n",
              "sampleID                                                        CCIS00146684ST-4-0   \n",
              "subjectID                                                                   fr-726   \n",
              "bodysite                                                                     stool   \n",
              "disease                                                                     cancer   \n",
              "...                                                                            ...   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...                               0   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...                               0   \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...                               0   \n",
              "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...                               0   \n",
              "k__Bacteria|p__Firmicutes|c__Negativicutes|o__S...                               0   \n",
              "\n",
              "                                                   freq  \n",
              "0                                                        \n",
              "dataset_name                                        121  \n",
              "sampleID                                              1  \n",
              "subjectID                                             1  \n",
              "bodysite                                            121  \n",
              "disease                                              48  \n",
              "...                                                 ...  \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  120  \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  117  \n",
              "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  120  \n",
              "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  120  \n",
              "k__Bacteria|p__Firmicutes|c__Negativicutes|o__S...  120  \n",
              "\n",
              "[714 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-967c70a2-4dcc-4719-a9c7-477f2a707985\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dataset_name</th>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>Zeller_fecal_colorectal_cancer</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sampleID</th>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>CCIS00146684ST-4-0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subjectID</th>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>fr-726</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodysite</th>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>stool</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disease</th>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>cancer</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Bavariicoccus|s__Bavariicoccus_seileri</th>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Enterococcus|s__Enterococcus_gilvus</th>\n",
              "      <td>121</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_otakiensis</th>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum|s__Desulfotomaculum_ruminis</th>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k__Bacteria|p__Firmicutes|c__Negativicutes|o__Selenomonadales|f__Veillonellaceae|g__Megasphaera|s__Megasphaera_sp_BV3C16_1</th>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-967c70a2-4dcc-4719-a9c7-477f2a707985')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-967c70a2-4dcc-4719-a9c7-477f2a707985 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-967c70a2-4dcc-4719-a9c7-477f2a707985');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0329af8a-c2f2-4eb3-8b24-1ae065c2cd46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0329af8a-c2f2-4eb3-8b24-1ae065c2cd46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0329af8a-c2f2-4eb3-8b24-1ae065c2cd46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"sample\",\n  \"rows\": 714,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"121\",\n        \"max\": \"121\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"121\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 121,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"Zeller_fecal_colorectal_cancer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"freq\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1\",\n        \"max\": \"121\",\n        \"num_unique_values\": 105,\n        \"samples\": [\n          \"77\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Process\n",
        "\n",
        "According to the original paper, the data provided in the codebase have been preprocessed and cleaned properly. We only need to extract the labels columns with feature index indentifier to get `X`. Also, we get `Y` from the `disease` column. This step is implemented in the `loadData` function of class `DeepMiccrobiome` in the Model session below.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QTkZz-HrofL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Use\n",
        "\n",
        "Given the running time of dimensionality reduction is long, we choose to only use the first 10 features of each dataset in order to control the total latency in this draft project."
      ],
      "metadata": {
        "id": "xk5NZf3ToGy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it.\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "An autoencoder represents a type of neural network designed for the purpose of reconstructing its input data, denoted as $x$. In its fundamental structure, it comprises an encoder function, denoted as $f_\\phi(⋅)$, and a decoder function, denoted as $f_\\theta′(⋅)$, with $\\phi$ and $\\theta$ serving as the parameters associated with the encoder and decoder functions, respectively.\n",
        "The training objective of an autoencoder is to minimize the disparity between the original input $x$ and its reconstructed counterpart $x′$. This discrepancy, typically quantified using a reconstruction loss metric such as squared error, can be mathematically expressed as $L(x, x')=||x-x'||^2=||x-f_\\theta'(f_\\phi(x))||^2$.\n",
        "\n",
        "In this project, we focus on the utilization of a trained autoencoder to obtain a lower-dimensional latent representation $z = f_\\phi(x)$ of the input. There are four autoencoders that we incorporate as below.\n",
        "\n",
        "1. Shallow Autoencoder (SAE): a fully connected encoder connecting the input layer to the latent layer, and a decoder producing the reconstructed input $x′$ by combining the outputs of the latent layer using weighted sums, with both the latent and output layers utilizing a linear activation function.\n",
        "\n",
        "2. Deep Autoencoder (DAE): enhanced SAE model by inserting hidden layers with Rectified Linear Unit (ReLu) activation function and Glorot uniform initializer between the input and latent layers, maintaining an equal number of hidden layers (either one or two layers) in both the encoder and decoder sections.\n",
        "\n",
        "3. Variational autoencoder (VAE): it learns probabilistic representations $z$ by approximating the true posterior distribution with $q_\\phi(z|x)$ assuming a Gaussian distribution. The encoder encodes the means and variances of the Gaussian distribution, allowing sampling of latent representation $z$. This sampled representation is then fed into the decoder network to generate the reconstructed input $x′ \\sim g_\\theta(x|z)$.\n",
        "\n",
        "4. convolutional autoencoder (CAE): equipped with convolutional layers where each unit is connected locally to the previous layer. The layers consist of multiple filters with weights for convolution operations. We employed ReLu activation, Glorot uniform initializer, and avoided pooling layers to prevent excessive generalization. The $n$-dimensional input vector was reshaped into a squared image of size $d \\times d \\times 1$, where $d = ⌊ \\sqrt{n} ⌋ + 1$.\n",
        "\n",
        "After getting the low-dimentional representations of profiles, we build classification models.\n",
        "\n",
        "1. Support Vector Machine (SVM): a grid search using SVM is conducted to explore the hyper-parameter space. We considered both radial basis function (RBF) and linear kernels, adjusting penalty parameter C and kernel coefficient gamma for RBF.\n",
        "\n",
        "2. Random Forest (RF): We examine two criteria, Gini impurity and information gain, for selecting features to split a node in a decision tree. The maximum number of features considered for the best split at each node was determined using the square root of the sample size and the logarithm to base 2 of the sample size.\n",
        "\n",
        "3. Multi-Layer Perceptron (MLP): ReLu activations were used for the hidden layers, while the output layer employed sigmoid activation with a single unit. The number of units in the hidden layers was set to half of the preceding layer, excluding the first hidden layer.\n",
        "\n",
        "The overall workflow is demonstrated in the Figure 1 below.\n",
        "\n",
        "![](\"assets/Model_Figure1.png\")\n",
        "\n",
        "### Training Objectives\n",
        "- Split each dataset into a training set, validation set, and test set (64% training, 16% validation, and 20% test).\n",
        "- Exclude the test set from model training.\n",
        "- Implement early-stopping strategy: train models on the training set, compute reconstruction loss for the validation set after each epoch, stop training if no improvement in validation loss is observed for 20 epochs.\n",
        "- Select the model with the lowest validation loss as the best model.\n",
        "Utilize mean squared error as the reconstruction loss metric.\n",
        "- Apply adaptive moment estimation (Adam) optimizer with default parameters (learning rate: 0.001, epsilon: 1e-07) as specified in the original paper.\n",
        "- Utilize the encoder part of the best model to generate low-dimensional representations of microbiome data for subsequent disease prediction tasks.\n",
        "\n",
        "\n",
        "### Evaluations\n",
        "\n",
        "- Conduct 5-fold cross-validation on the reduced training set. This involves dividing the training set into five subsets, using four subsets for training and one for validation in each fold. This is to vary hyper-parameters and explore different combinations to find the best performing configuration.\n",
        "- Evaluate the performance of the models using the area under the receiver operating characteristics curve (AUC). This metric assesses the model's ability to distinguish between different classes and is commonly used for classification tasks.\n",
        "- Train a final classification model using the entire training set and the best hyper-parameter combination identified during cross-validation. This model aims to achieve optimal performance based on the selected configuration. Then test the final classification model on the separate test set, which was not used during training. This evaluation provides an unbiased assessment of the model's performance on unseen data.\n",
        "- Repeat the entire procedure five times, each time using a different random partition seed to create new training, validation, and test sets. This helps account for potential variations in performance due to the specific data splits. Average the resulting AUC scores obtained from the five repetitions. This average serves as a summary metric to compare the performance of different models or approaches. It provides a more robust assessment by considering multiple iterations of the evaluation process."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters Config\n",
        "\n",
        "The original implementation use command line arguments to facilitate the execution of experiments with varying configurations. In order to enhance usability within a Colab notebook environment, we modified this approach by introducing a configuration object, which offers a more convenient and intuitive means of manipulating settings. The structures of configs is as below.\n",
        "\n",
        "```\n",
        ".\n",
        "├── ...\n",
        "├── data                                      # Data folder\n",
        "├── experiment_configs                        # Config folder\n",
        "│       ├── vae_config.json                   # Config uses Variational Autoencoder (VAE)\n",
        "│       ├── cae_config.json                   # Config uses Convolutional Autoencoder (CAE):\n",
        "│       ├── ae_config.json                    # Config uses Shallow Autoencoder (SAE) or Deep Autoencoder (DAE)\n",
        "│       ├── default_experiment_config.json    # Baseline configs\n",
        "│       ├── test_experiment_config_1.json     # Test config of no autoencoder\n",
        "└── ...\n",
        "```"
      ],
      "metadata": {
        "id": "RR6vBH8DsFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment config dir\n",
        "experiments_config_dir = '/content/drive/My Drive/Colab Notebooks/experiment_configs'\n",
        "\n",
        "# set up config class for loading json experiment configs\n",
        "class DeepMicro_Config(object):\n",
        "  def __init__(self, config_name=None, config_dict=None):\n",
        "    if config_dict:\n",
        "      self.load_from_dict(config_dict)\n",
        "    elif config_name:\n",
        "      self.load_from_file(experiments_config_dir + \"/\" + config_name + \".json\")\n",
        "\n",
        "  def load_from_dict(self, dictionary):\n",
        "    for key, value in dictionary.items():\n",
        "      if isinstance(value, dict):\n",
        "        value = DeepMicro_Config(config_dict=value)\n",
        "      self.__dict__[key] = value\n",
        "\n",
        "  def load_from_file(self, config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "      config_dict = json.load(f)\n",
        "    self.load_from_dict(config_dict)\n",
        "\n",
        "  def __getattr__(self, attr):\n",
        "    return self.__dict__.get(attr, None)\n",
        "\n",
        "# dict for data_type in config\n",
        "dtypeDict = {\"float16\": np.float16, \"float32\": np.float32, \"float64\": np.float64}\n",
        "\n",
        "# set labels for diseases and controls\n",
        "label_dict = {\n",
        "  # Controls\n",
        "  'n': 0,\n",
        "  # Chirrhosis\n",
        "  'cirrhosis': 1,\n",
        "  # Colorectal Cancer\n",
        "  'cancer': 1, 'small_adenoma': 0,\n",
        "  # IBD\n",
        "  'ibd_ulcerative_colitis': 1, 'ibd_crohn_disease': 1,\n",
        "  # T2D and WT2D\n",
        "  't2d': 1,\n",
        "  # Obesity\n",
        "  'leaness': 0, 'obesity': 1,\n",
        "}\n",
        "\n",
        "# hyper-parameter grids for classifiers\n",
        "# TODO: set n_estimator range(100, 1001, 200), here is only for draft\n",
        "# TODO: set min_samples_leaf range(1,6), here is only for draft\n",
        "rf_hyper_parameters = [{'n_estimators': [s for s in range(500, 1000, 500)],\n",
        "                        'max_features': ['sqrt', 'log2'],\n",
        "                        'min_samples_leaf': [2], # [1, 2, 3, 4, 5],\n",
        "                        'criterion': ['gini', 'entropy']\n",
        "                        }, ]\n",
        "\n",
        "#svm_hyper_parameters_pasolli = [{'C': [2 ** s for s in range(-5, 16, 2)], 'kernel': ['linear']},\n",
        "#                        {'C': [2 ** s for s in range(-5, 16, 2)], 'gamma': [2 ** s for s in range(3, -15, -2)],\n",
        "#                         'kernel': ['rbf']}]\n",
        "\n",
        "# TODO: set C range(-5, 6, 2), here is only for draft\n",
        "# TODO: set gamma range(3, -15, -2), here is only for draft\n",
        "svm_hyper_parameters = [\n",
        "    {\n",
        "        'C': [2 ** s for s in [-2]],\n",
        "        'kernel': ['linear']\n",
        "        },\n",
        "    {\n",
        "        'C': [2 ** s for s in [-2]],\n",
        "        'gamma': [2 ** s for s in range(1, -4, -2)],\n",
        "        'kernel': ['rbf']\n",
        "        }\n",
        "    ]\n",
        "# TODO: set numHiddenLayers [1, 2, 3], here is only for draft\n",
        "# TODO: set epoch larger in final project, 30 is only for draft\n",
        "# TODO: set numUnits larger in final project, 10 is only for draft\n",
        "mlp_hyper_parameters = [{'numHiddenLayers': [2],\n",
        "                         'epochs': [30], # [30, 50, 100, 200, 300],\n",
        "                         'numUnits': [10], # [10, 30, 50, 100],\n",
        "                         'dropout_rate': [0.1, 0.3],\n",
        "                         },]\n"
      ],
      "metadata": {
        "id": "BHu3D1U5sF03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoders Definitions\n",
        "\n"
      ],
      "metadata": {
        "id": "c3XEF8AmtwSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder\n",
        "def autoencoder(dims, act='relu', init='glorot_uniform', latent_act = False, output_act = False):\n",
        "    \"\"\"\n",
        "        Fully connected auto-encoder model, symmetric.\n",
        "        Arguments:\n",
        "            dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
        "                The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
        "            act: activation, not applied to Input, Hidden and Output layers\n",
        "        return:\n",
        "            (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
        "        \"\"\"\n",
        "\n",
        "    # whether put activation function in latent layer\n",
        "    if latent_act:\n",
        "        l_act = act\n",
        "    else:\n",
        "        l_act = None\n",
        "\n",
        "    if output_act:\n",
        "        o_act = 'sigmoid'\n",
        "    else:\n",
        "        o_act = None\n",
        "\n",
        "    # The number of internal layers: layers between input and latent layer\n",
        "    n_internal_layers = len(dims) - 2\n",
        "\n",
        "    # input\n",
        "    x = Input(shape=(dims[0],), name='input')\n",
        "    h = x\n",
        "\n",
        "    # internal layers in encoder\n",
        "    for i in range(n_internal_layers):\n",
        "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(h)\n",
        "\n",
        "    # bottle neck layer, features are extracted from here\n",
        "    h = Dense(dims[-1], activation=l_act, kernel_initializer=init, name='encoder_%d_bottle-neck' % (n_internal_layers))(h)\n",
        "\n",
        "    y = h\n",
        "\n",
        "    # internal layers in decoder\n",
        "    for i in range(n_internal_layers, 0, -1):\n",
        "        y = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(y)\n",
        "\n",
        "    # output\n",
        "    y = Dense(dims[0], activation=o_act, kernel_initializer=init, name='decoder_0')(y)\n",
        "\n",
        "    return Model(inputs=x, outputs=y, name='AE'), Model(inputs=x, outputs=h, name='encoder')"
      ],
      "metadata": {
        "id": "pWkNlD2ORZoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional autoencoder\n",
        "def conv_autoencoder(dims, act='relu', init='glorot_uniform', latent_act = False, output_act = False, rf_rate = 0.1, st_rate = 0.25):\n",
        "    # whether put activation function in latent layer\n",
        "    if latent_act:\n",
        "        l_act = act\n",
        "    else:\n",
        "        l_act = None\n",
        "\n",
        "    if output_act:\n",
        "        o_act = 'sigmoid'\n",
        "    else:\n",
        "        o_act = None\n",
        "\n",
        "    # receptive field and stride size\n",
        "    rf_size = init_rf_size = int(dims[0][0] * rf_rate)\n",
        "    if rf_size <= 0:\n",
        "        print(f\"Warning: Computed rf_size is {rf_size}, which is not valid. Setting to default value 3.\")\n",
        "        rf_size = 3  # Default fallback value\n",
        "    stride_size = init_stride_size = int(rf_size * st_rate) if int(rf_size * st_rate) > 0 else 1\n",
        "    print(\"receptive field (kernel) size: %d\" % rf_size)\n",
        "    print(\"stride size: %d\" % stride_size)\n",
        "\n",
        "    # The number of internal layers: layers between input and latent layer\n",
        "    n_internal_layers = len(dims) - 1\n",
        "\n",
        "    if n_internal_layers < 1:\n",
        "        print(\"The number of internal layers for CAE should be greater than or equal to 1\")\n",
        "        exit()\n",
        "\n",
        "    # input\n",
        "    x = Input(shape=dims[0], name='input')\n",
        "    h = x\n",
        "\n",
        "    rf_size_list = []\n",
        "    stride_size_list = []\n",
        "    # internal layers in encoder\n",
        "    for i in range(n_internal_layers):\n",
        "        print(\"rf_size: %d, st_size: %d\" % (rf_size, stride_size))\n",
        "        h = Conv2D(\n",
        "            dims[max(i + 1, len(dims)-1)], (rf_size,rf_size),\n",
        "            strides=(stride_size, stride_size), activation=act,\n",
        "            padding='same', kernel_initializer=init,\n",
        "            name='encoder_conv_%d' % i)(h)\n",
        "        #h = MaxPool2D((2,2), padding='same')(h)\n",
        "        rf_size = int(K.int_shape(h)[1] * rf_rate)\n",
        "        stride_size = int(rf_size /2.) if int(rf_size /2.) > 0 else 1\n",
        "        rf_size_list.append(rf_size)\n",
        "        stride_size_list.append(stride_size)\n",
        "\n",
        "    reshapeDim = K.int_shape(h)[1:]\n",
        "\n",
        "    # bottle neck layer, features are extracted from h\n",
        "    h = Flatten()(h)\n",
        "\n",
        "    y = h\n",
        "\n",
        "    y = Reshape(reshapeDim)(y)\n",
        "\n",
        "    print(rf_size_list)\n",
        "    print(stride_size_list)\n",
        "\n",
        "    # internal layers in decoder\n",
        "    for i in range(n_internal_layers - 1, 0, -1):\n",
        "        y = Conv2DTranspose(dims[i], (rf_size_list[i-1],rf_size_list[i-1]), strides=(stride_size_list[i-1], stride_size_list[i-1]), activation=act, padding='same', kernel_initializer=init, name='decoder_conv_%d' % i)(y)\n",
        "        #y = UpSampling2D((2,2))(y)\n",
        "\n",
        "    y = Conv2DTranspose(1, (init_rf_size, init_rf_size), strides=(init_stride_size, init_stride_size), activation=o_act, kernel_initializer=init, padding='same', name='decoder_1')(y)\n",
        "\n",
        "    # output cropping\n",
        "    if K.int_shape(x)[1] != K.int_shape(y)[1]:\n",
        "        cropping_size = K.int_shape(y)[1] - K.int_shape(x)[1]\n",
        "        y = Cropping2D(cropping=((cropping_size, 0), (cropping_size, 0)), data_format=None)(y)\n",
        "\n",
        "    #print(\"dims[0]: %s\" % str(dims[0]))\n",
        "\n",
        "    # output\n",
        "    # y = Conv2D(1, (rf_size, rf_size), activation=o_act, kernel_initializer=init, padding='same', name='decoder_1')(y)\n",
        "    #\n",
        "    # outputDim = reshapeDim * (2 ** n_internal_layers)\n",
        "    # if outputDim != dims[0][0]:\n",
        "    #     cropping_size = outputDim - dims[0][0]\n",
        "    #     #print(outputDim, dims[0][0], cropping_size)\n",
        "    #     y = Cropping2D(cropping=((cropping_size, 0), (cropping_size, 0)), data_format=None)(y)\n",
        "\n",
        "\n",
        "    return Model(inputs=x, outputs=y, name='CAE'), Model(inputs=x, outputs=h, name='encoder')\n"
      ],
      "metadata": {
        "id": "79KCL-48RxbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(Model):\n",
        "    def __init__(self, dims, activation='relu', initializer='glorot_uniform', output_activation=False, recon_loss='mse', beta=1):\n",
        "        super(VAE, self).__init__()\n",
        "        self.beta = beta\n",
        "        self.output_activation = 'sigmoid' if output_activation else None\n",
        "        self.recon_loss_fn = MeanSquaredError() if recon_loss == 'mse' else BinaryCrossentropy()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = self.build_encoder(dims, activation, initializer)\n",
        "        # Decoder\n",
        "        self.decoder = self.build_decoder(dims, activation, initializer, self.output_activation)\n",
        "\n",
        "    def build_encoder(self, dims, activation, initializer):\n",
        "        inputs = Input(shape=(dims[0],))\n",
        "        x = inputs\n",
        "        for size in dims[1:-1]:\n",
        "            x = Dense(size, activation=activation, kernel_initializer=initializer)(x)\n",
        "        z_mean = Dense(dims[-1], name='z_mean')(x)\n",
        "        z_log_var = Dense(dims[-1], name='z_log_var')(x)\n",
        "        z = Lambda(self.sampling, output_shape=(dims[-1],), name='z')([z_mean, z_log_var])\n",
        "        return Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "    def build_decoder(self, dims, activation, initializer, output_activation):\n",
        "        latent_inputs = Input(shape=(dims[-1],))\n",
        "        x = latent_inputs\n",
        "        for size in reversed(dims[1:-1]):\n",
        "            x = Dense(size, activation=activation, kernel_initializer=initializer)(x)\n",
        "        outputs = Dense(dims[0], activation=output_activation)(x)\n",
        "        return Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "    def sampling(self, args):\n",
        "        z_mean, z_log_var = args\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = z_mean.shape[1]\n",
        "        epsilon = tf.random.normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        # Add KL divergence regularization loss.\n",
        "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1)) * -0.5 * self.beta\n",
        "        self.add_loss(kl_loss)\n",
        "        # Add reconstruction loss\n",
        "        reconstruction_loss = self.recon_loss_fn(inputs, reconstructed) * tf.cast(tf.shape(inputs)[1], tf.float32)\n",
        "        self.add_loss(reconstruction_loss)\n",
        "        return reconstructed\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = self(data, training=True)\n",
        "            loss = sum(self.losses)\n",
        "        grads = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        return {\"loss\": loss}"
      ],
      "metadata": {
        "id": "s2hbJUcCjiEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron"
      ],
      "metadata": {
        "id": "I1LI2I3puU3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create MLP model\n",
        "def mlp_model(input_dim, numHiddenLayers=3, numUnits=64, dropout_rate=0.5):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    #Check number of hidden layers\n",
        "    if numHiddenLayers >= 1:\n",
        "        # First Hidden layer\n",
        "        model.add(Dense(numUnits, input_dim=input_dim, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "        # Second to the last hidden layers\n",
        "        for i in range(numHiddenLayers - 1):\n",
        "            numUnits = numUnits // 2\n",
        "            model.add(Dense(numUnits, activation='relu'))\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "        # output layer\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    else:\n",
        "        # output layer\n",
        "        model.add(Dense(1, input_dim=input_dim, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', )#metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "yMryKTfuVulb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Models"
      ],
      "metadata": {
        "id": "LS3jIzt9uj9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepMicrobiome(object):\n",
        "  # TODO:  THIS WHOLE CLASS\n",
        "  # This is where the bulk of the logic for the project goes\n",
        "  def __init__(self, data, seed, data_dir):\n",
        "    self.t_start = time.time()\n",
        "    self.filename = str(data)\n",
        "    self.data = self.filename.split('.')[0]\n",
        "    self.seed = seed\n",
        "    self.data_dir = data_dir\n",
        "    self.prefix = ''\n",
        "    self.representation_only = False\n",
        "\n",
        "  def loadData(self, feature_string, label_string, label_dict, dtype=None):\n",
        "    # read file\n",
        "    filename = self.data_dir + self.filename\n",
        "    if os.path.isfile(filename):\n",
        "      raw = pd.read_csv(filename, sep='\\t', index_col=0, header=None)\n",
        "    else:\n",
        "      print(\"FileNotFoundError: File {} does not exist\".format(filename))\n",
        "      exit()\n",
        "\n",
        "    #DEBUG\n",
        "    print(\"loaded data from \" + str(filename))\n",
        "\n",
        "    # TODO: draft project only considers first 10 features\n",
        "\n",
        "    # select rows having feature index identifier string\n",
        "    X = raw.loc[raw.index.str.contains(feature_string, regex=False)].T\n",
        "    X = X.iloc[:, :10]\n",
        "\n",
        "    # get class labels\n",
        "    Y = raw.loc[label_string] #'disease'\n",
        "    Y = Y.replace(label_dict)\n",
        "\n",
        "    # train and test split\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X.values.astype(dtype), Y.values.astype('int'), test_size=0.2, random_state=self.seed, stratify=Y.values)\n",
        "    self.printDataShapes()\n",
        "\n",
        "  def loadCustomData(self, dtype=None):\n",
        "    # read file\n",
        "    filename = self.data_dir + \"data/\" + self.filename\n",
        "    if os.path.isfile(filename):\n",
        "      raw = pd.read_csv(filename, sep=',', index_col=False, header=None)\n",
        "    else:\n",
        "      print(\"FileNotFoundError: File {} does not exist\".format(filename))\n",
        "      exit()\n",
        "\n",
        "    # load data\n",
        "    self.X_train = raw.values.astype(dtype)\n",
        "\n",
        "    # put nothing or zeros for y_train, y_test, and X_test\n",
        "    self.y_train = np.zeros(shape=(self.X_train.shape[0])).astype(dtype)\n",
        "    self.X_test = np.zeros(shape=(1,self.X_train.shape[1])).astype(dtype)\n",
        "    self.y_test = np.zeros(shape=(1,)).astype(dtype)\n",
        "    self.printDataShapes(train_only=True)\n",
        "\n",
        "  def loadCustomDataWithLabels(self, label_data, dtype=None):\n",
        "    # read file\n",
        "    filename = self.data_dir + \"data/\" + self.filename\n",
        "    label_filename = self.data_dir + \"data/\" + label_data\n",
        "    if os.path.isfile(filename) and os.path.isfile(label_filename):\n",
        "      raw = pd.read_csv(filename, sep=',', index_col=False, header=None)\n",
        "      label = pd.read_csv(label_filename, sep=',', index_col=False, header=None)\n",
        "    else:\n",
        "      if not os.path.isfile(filename):\n",
        "        print(\"FileNotFoundError: File {} does not exist\".format(filename))\n",
        "      if not os.path.isfile(label_filename):\n",
        "        print(\"FileNotFoundError: File {} does not exist\".format(label_filename))\n",
        "      exit()\n",
        "\n",
        "    # label data validity check\n",
        "    if not label.values.shape[1] > 1:\n",
        "      label_flatten = label.values.reshape((label.values.shape[0]))\n",
        "    else:\n",
        "      print('FileSpecificationError: The label file contains more than 1 column.')\n",
        "      exit()\n",
        "\n",
        "    # train and test split\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(raw.values.astype(dtype),\n",
        "                                                                            label_flatten.astype('int'), test_size=0.2,\n",
        "                                                                            random_state=self.seed,\n",
        "                                                                            stratify=label_flatten)\n",
        "    self.printDataShapes()\n",
        "\n",
        "  # Principal Component Analysis\n",
        "  def pca(self, ratio=0.99):\n",
        "    # manipulating an experiment identifier in the output file\n",
        "    self.prefix = self.prefix + 'PCA_'\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA()\n",
        "    pca.fit(self.X_train)\n",
        "    n_comp = 0\n",
        "    ratio_sum = 0.0\n",
        "\n",
        "    for comp in pca.explained_variance_ratio_:\n",
        "      ratio_sum += comp\n",
        "      n_comp += 1\n",
        "      if ratio_sum >= ratio:  # Selecting components explaining 99% of variance\n",
        "        break\n",
        "\n",
        "    pca = PCA(n_components=n_comp)\n",
        "    pca.fit(self.X_train)\n",
        "\n",
        "    X_train = pca.transform(self.X_train)\n",
        "    X_test = pca.transform(self.X_test)\n",
        "\n",
        "    # applying the eigenvectors to the whole training and the test set.\n",
        "    self.X_train = X_train\n",
        "    self.X_test = X_test\n",
        "    self.printDataShapes()\n",
        "\n",
        "  # Gausian Random Projection\n",
        "  def rp(self):\n",
        "    # manipulating an experiment identifier in the output file\n",
        "    self.prefix = self.prefix + 'RandP_'\n",
        "    # GRP\n",
        "    rf = GaussianRandomProjection(eps=0.5)\n",
        "    rf.fit(self.X_train)\n",
        "\n",
        "    # applying GRP to the whole training and the test set.\n",
        "    self.X_train = rf.transform(self.X_train)\n",
        "    self.X_test = rf.transform(self.X_test)\n",
        "    self.printDataShapes()\n",
        "\n",
        "  # Shallow Autoencoder & Deep Autoencoder\n",
        "  # TODO: set epochs=2000 in final project, 20 is only for draft\n",
        "  def ae(self, dims=[50], epochs=2000, batch_size=100, verbose=2, loss='mean_squared_error',\n",
        "           latent_act=False, output_act=False, act='relu', patience=20, val_rate=0.2, no_trn=False):\n",
        "        # Adjusting experiment identifier\n",
        "        prefix = 'AE' if len(dims) == 1 else 'DAE'\n",
        "        suffix = f\"{loss[:1]}{'t' if latent_act else ''}{'T' if output_act else ''}_{act[:1]}\"\n",
        "        model_id = f\"{prefix}_{suffix}_{str(dims).replace(', ', '-')}\"\n",
        "\n",
        "        # File name for the model checkpoint\n",
        "        modelName = f\"{model_id}_{self.data}.keras\"\n",
        "\n",
        "        # Clean up model checkpoint before use\n",
        "        if os.path.exists(modelName):\n",
        "            os.remove(modelName)\n",
        "\n",
        "        # Callbacks for early stopping and model checkpoint\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=patience, mode='min', verbose=1),\n",
        "            ModelCheckpoint(modelName, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "        ]\n",
        "\n",
        "        # Prepare data splits\n",
        "        X_inner_train, X_inner_test, y_inner_train, y_inner_test = train_test_split(\n",
        "            self.X_train, self.y_train, test_size=val_rate, random_state=self.seed, stratify=self.y_train\n",
        "        )\n",
        "\n",
        "        # Autoencoder model architecture\n",
        "        input_layer = Input(shape=(X_inner_train.shape[1],))\n",
        "        x = input_layer\n",
        "        for dim in dims:\n",
        "            x = Dense(dim, activation=act)(x)\n",
        "        if latent_act:\n",
        "            x = Dense(dims[-1], activation='tanh')(x)  # Example latent activation\n",
        "        reconstructed = Dense(X_inner_train.shape[1], activation='sigmoid' if output_act else 'linear')(x)\n",
        "\n",
        "        autoencoder = Model(inputs=input_layer, outputs=reconstructed)\n",
        "        autoencoder.compile(optimizer='adam', loss=loss)\n",
        "        autoencoder.summary()\n",
        "\n",
        "        if no_trn:\n",
        "            return\n",
        "\n",
        "        # Model training\n",
        "        self.history = autoencoder.fit(\n",
        "            X_inner_train, X_inner_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=verbose,\n",
        "            validation_data=(X_inner_test, X_inner_test)\n",
        "        )\n",
        "\n",
        "        # Load the best model\n",
        "        autoencoder.load_weights(modelName)\n",
        "\n",
        "        # Extract the encoder model\n",
        "        encoder_layer_index = int(len(autoencoder.layers) / 2)  # Assuming the encoder is the first half\n",
        "        encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[encoder_layer_index].output)\n",
        "\n",
        "        # Apply the learned encoder to the training and test sets\n",
        "        self.X_train = encoder.predict(self.X_train)\n",
        "        self.X_test = encoder.predict(self.X_test)\n",
        "\n",
        "        self.saveLossProgress()\n",
        "\n",
        "  # Variational Autoencoder\n",
        "  # TODO: set epochs=2000 in final project, 20 is only for draft\n",
        "  def vae(self, dims = [10], epochs=20, batch_size=100, verbose=2, loss='mse', output_act=False, act='relu', patience=25, beta=1.0, warmup=True, warmup_rate=0.01, val_rate=0.2, no_trn=False):\n",
        "\n",
        "        # manipulating an experiment identifier in the output file\n",
        "        if patience != 25:\n",
        "            self.prefix += 'p' + str(patience) + '_'\n",
        "        if warmup:\n",
        "            self.prefix += 'w' + str(warmup_rate) + '_'\n",
        "        self.prefix += 'VAE'\n",
        "        if loss == 'binary_crossentropy':\n",
        "            self.prefix += 'b'\n",
        "        if output_act:\n",
        "            self.prefix += 'T'\n",
        "        if beta != 1:\n",
        "            self.prefix += 'B' + str(beta)\n",
        "        self.prefix += str(dims).replace(\", \", \"-\") + '_'\n",
        "        if act == 'sigmoid':\n",
        "            self.prefix += 'sig_'\n",
        "\n",
        "        # filename for temporary model checkpoint\n",
        "        modelName = self.prefix + self.data + '.weights.h5'\n",
        "\n",
        "        # clean up model checkpoint before use\n",
        "        if os.path.isfile(modelName):\n",
        "            os.remove(modelName)\n",
        "\n",
        "        # callbacks for each epoch\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience, mode='min', verbose=1),\n",
        "                     ModelCheckpoint(modelName, monitor='val_loss', mode='min', verbose=1, save_best_only=True,save_weights_only=True)]\n",
        "\n",
        "        # warm-up callback\n",
        "        warm_up_cb = LambdaCallback(on_epoch_end=lambda epoch, logs: [warm_up(epoch)])  # , print(epoch), print(K.get_value(beta))])\n",
        "\n",
        "        # warm-up implementation\n",
        "        def warm_up(epoch):\n",
        "            val = epoch * warmup_rate\n",
        "            if val <= 1.0:\n",
        "                K.set_value(beta, val)\n",
        "        # add warm-up callback if requested\n",
        "        if warmup:\n",
        "            beta = K.variable(value=0.0)\n",
        "            callbacks.append(warm_up_cb)\n",
        "\n",
        "        # spliting the training set into the inner-train and the inner-test set (validation set)\n",
        "        X_inner_train, X_inner_test, y_inner_train, y_inner_test = train_test_split(self.X_train, self.y_train,\n",
        "                                                                                    test_size=val_rate,\n",
        "                                                                                    random_state=self.seed,\n",
        "                                                                                    stratify=self.y_train)\n",
        "\n",
        "        # insert input shape into dimension list\n",
        "        dims.insert(0, X_inner_train.shape[1])\n",
        "\n",
        "        # create vae model\n",
        "        # self.vae, self.encoder, self.decoder = variational_AE(dims, act=act, recon_loss=loss, output_act=output_act, beta=beta)\n",
        "        self.vae = VAE(dims, activation=act, recon_loss=loss, output_activation=output_act, beta=beta)\n",
        "        self.vae.compile(optimizer='adam')\n",
        "        self.encoder = self.vae.encoder\n",
        "        self.decoder = self.vae.decoder\n",
        "        self.vae.summary()\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "\n",
        "        if no_trn:\n",
        "            return\n",
        "\n",
        "        # fit\n",
        "        self.history = self.vae.fit(X_inner_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=verbose, validation_data=(X_inner_test, None))\n",
        "\n",
        "        # save loss progress\n",
        "        self.saveLossProgress()\n",
        "\n",
        "        # load best model\n",
        "        self.vae.load_weights(modelName)\n",
        "        # self.encoder = self.vae.layers[1]\n",
        "        self.encoder = self.vae.encoder\n",
        "\n",
        "        # applying the learned encoder into the whole training and the test set.\n",
        "        _, _, self.X_train = self.encoder.predict(self.X_train)\n",
        "        _, _, self.X_test = self.encoder.predict(self.X_test)\n",
        "\n",
        "\n",
        "  # Convolutional Autoencoder\n",
        "  # TODO: set epochs=2000 in final project, 20 is only for draft\n",
        "  def cae(self, dims=[32], epochs=20, batch_size=100, verbose=2, loss='mse', output_act=False, act='relu', patience=25, val_rate=0.2, rf_rate=0.1, st_rate=0.25, no_trn=False):\n",
        "      # Manipulating an experiment identifier in the output file\n",
        "      self.prefix += 'CAE'\n",
        "      if loss == 'binary_crossentropy':\n",
        "          self.prefix += 'b'\n",
        "      if output_act:\n",
        "          self.prefix += 'T'\n",
        "      self.prefix += str(dims).replace(\", \", \"-\") + '_'\n",
        "      if act == 'sigmoid':\n",
        "          self.prefix += 'sig_'\n",
        "\n",
        "      # Filename for temporary model checkpoint\n",
        "      modelName = self.data_dir + self.prefix + self.data + '.weights.h5'\n",
        "\n",
        "      # Clean up model checkpoint before use\n",
        "      if os.path.isfile(modelName):\n",
        "          os.remove(modelName)\n",
        "\n",
        "      # Prepare the dataset for convolutional operations\n",
        "      onesideDim = int(math.sqrt(self.X_train.shape[1])) + 1\n",
        "      enlargedDim = onesideDim ** 2\n",
        "      self.X_train = np.pad(self.X_train, ((0, 0), (0, enlargedDim - self.X_train.shape[1])), 'constant')\n",
        "      self.X_test = np.pad(self.X_test, ((0, 0), (0, enlargedDim - self.X_test.shape[1])), 'constant')\n",
        "\n",
        "      self.X_train = self.X_train.reshape((-1, onesideDim, onesideDim, 1))\n",
        "      self.X_test = self.X_test.reshape((-1, onesideDim, onesideDim, 1))\n",
        "\n",
        "      self.printDataShapes()\n",
        "\n",
        "      # Callbacks for early stopping and model checkpoint\n",
        "      callbacks = [\n",
        "          EarlyStopping(monitor='val_loss', patience=patience, mode='min', verbose=1),\n",
        "          ModelCheckpoint(modelName, monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "      ]\n",
        "\n",
        "      # Model architecture using functional API\n",
        "      input_shape = (onesideDim, onesideDim, 1)\n",
        "      inputs = Input(shape=input_shape)\n",
        "      x = inputs\n",
        "      for dim in dims:\n",
        "          x = Conv2D(dim, (3, 3), activation=act, padding='same')(x)\n",
        "          x = Conv2D(dim, (3, 3), activation=act, padding='same', strides=(2, 2))(x)  # downsampling\n",
        "      encoded = Flatten()(x)\n",
        "      x = Dense(encoded.shape[1], activation=act)(encoded)  # bottleneck layer\n",
        "      x = Reshape((onesideDim // 2 ** len(dims), onesideDim // 2 ** len(dims), dims[-1]))(x)\n",
        "      for dim in reversed(dims):\n",
        "          x = Conv2DTranspose(dim, (3, 3), activation=act, padding='same', strides=(2, 2))(x)  # upsampling\n",
        "      decoded = Conv2DTranspose(1, (3, 3), activation='sigmoid' if output_act else 'linear', padding='same')(x)\n",
        "\n",
        "      autoencoder = Model(inputs, decoded)\n",
        "      autoencoder.compile(optimizer='adam', loss=loss)\n",
        "      autoencoder.summary()\n",
        "\n",
        "      if no_trn:\n",
        "          return\n",
        "\n",
        "      # Split the training set into the inner-train and the inner-test set (validation set)\n",
        "      X_inner_train, X_inner_test, _, _ = train_test_split(\n",
        "          self.X_train, self.y_train, test_size=val_rate, random_state=self.seed, stratify=self.y_train\n",
        "      )\n",
        "\n",
        "      # Fit model\n",
        "      self.history = autoencoder.fit(\n",
        "          X_inner_train, X_inner_train,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          callbacks=callbacks,\n",
        "          verbose=verbose,\n",
        "          validation_data=(X_inner_test, X_inner_test)\n",
        "      )\n",
        "\n",
        "      # Save loss progress\n",
        "      self.saveLossProgress()\n",
        "\n",
        "      # Load best model weights\n",
        "      autoencoder.load_weights(modelName)\n",
        "\n",
        "      # Reconstruct the encoder model from the autoencoder\n",
        "      encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(index=int(len(autoencoder.layers) / 2)).output)\n",
        "\n",
        "      # Apply the learned encoder to the whole training and test set\n",
        "      self.X_train = encoder.predict(self.X_train)\n",
        "      self.X_test = encoder.predict(self.X_test)\n",
        "      self.printDataShapes()\n",
        "\n",
        "\n",
        "  # Classification\n",
        "  def classification(self, hyper_parameters, method='svm', cv=5, scoring='roc_auc', n_jobs=1, cache_size=10000):\n",
        "    clf_start_time = time.time()\n",
        "\n",
        "    print(\"# Tuning hyper-parameters\")\n",
        "    print(self.X_train.shape, self.y_train.shape)\n",
        "\n",
        "    # Support Vector Machine\n",
        "    if method == 'svm':\n",
        "      clf = GridSearchCV(SVC(probability=True, cache_size=cache_size), hyper_parameters, cv=StratifiedKFold(cv, shuffle=True), scoring=scoring, n_jobs=n_jobs, verbose=100, )\n",
        "      clf.fit(self.X_train, self.y_train)\n",
        "\n",
        "    # Random Forest\n",
        "    if method == 'rf':\n",
        "      clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, random_state=0), hyper_parameters, cv=StratifiedKFold(cv, shuffle=True), scoring=scoring, n_jobs=n_jobs, verbose=100)\n",
        "      clf.fit(self.X_train, self.y_train)\n",
        "\n",
        "    # Multi-layer Perceptron\n",
        "    if method == 'mlp':\n",
        "      # TODO:  Implement the DNN model and use it here\n",
        "      print(\"mlp classifier todo\")\n",
        "      model = KerasClassifier(build_fn=mlp_model, input_dim=self.X_train.shape[1], verbose=0, dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10)\n",
        "      clf = GridSearchCV(estimator=model, param_grid=hyper_parameters, cv=StratifiedKFold(cv, shuffle=True), scoring=scoring, n_jobs=n_jobs, verbose=100)\n",
        "      clf.fit(self.X_train, self.y_train, batch_size=32)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "\n",
        "    # Evaluate performance of the best model on test set\n",
        "    y_true, y_pred = self.y_test, clf.predict(self.X_test)\n",
        "    y_prob = clf.predict_proba(self.X_test)\n",
        "\n",
        "    # Performance Metrics: AUC, ACC, Recall, Precision, F1_score\n",
        "    metrics = [ round(roc_auc_score(y_true, y_prob[:, 1]), 4),\n",
        "                round(accuracy_score(y_true, y_pred), 4),\n",
        "                round(recall_score(y_true, y_pred), 4),\n",
        "                round(precision_score(y_true, y_pred), 4),\n",
        "                round(f1_score(y_true, y_pred), 4), ]\n",
        "\n",
        "    # time stamp\n",
        "    metrics.append(str(datetime.datetime.now()))\n",
        "\n",
        "    # running time\n",
        "    metrics.append(round( (time.time() - self.t_start), 2))\n",
        "\n",
        "    # classification time\n",
        "    metrics.append(round( (time.time() - clf_start_time), 2))\n",
        "\n",
        "    # best hyper-parameter append\n",
        "    metrics.append(str(clf.best_params_))\n",
        "\n",
        "    # Write performance metrics as a file\n",
        "    # NOTE:  I HAVE DISABLED THIS FOR NOW TO JUST GET SIMPLE RUNNING WORKING, MAYBE LATER\n",
        "\n",
        "    res = pd.DataFrame([metrics], index=[self.prefix + method])\n",
        "    with open(self.data_dir + \"results/\" + self.data + \"_result.txt\", 'a') as f:\n",
        "     res.to_csv(f, header=None)\n",
        "\n",
        "    print('Accuracy metrics')\n",
        "    print('AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter')\n",
        "    print(metrics)\n",
        "\n",
        "  # Print debug info on data shape\n",
        "  def printDataShapes(self, train_only=False):\n",
        "      print(\"X_train.shape: \", self.X_train.shape)\n",
        "      if not train_only:\n",
        "        print(\"y_train.shape: \", self.y_train.shape)\n",
        "        print(\"X_test.shape: \", self.X_test.shape)\n",
        "        print(\"y_test.shape: \", self.y_test.shape)\n",
        "\n",
        "  # ploting loss progress over epochs\n",
        "  def saveLossProgress(self):\n",
        "    #print(self.history.history.keys())\n",
        "    #print(type(self.history.history['loss']))\n",
        "    #print(min(self.history.history['loss']))\n",
        "\n",
        "    loss_collector, loss_max_atTheEnd = self.saveLossProgress_ylim()\n",
        "\n",
        "    # create saving path\n",
        "    if not os.path.exists(os.path.join(self.data_dir, 'results')):\n",
        "      os.mkdir(os.path.join(self.data_dir, 'results'))\n",
        "\n",
        "    # save loss progress - train and val loss only\n",
        "    figureName = self.prefix + self.data + '_' + str(self.seed)\n",
        "    plt.ylim(min(loss_collector)*0.9, loss_max_atTheEnd * 2.0)\n",
        "    plt.plot(self.history.history['loss'])\n",
        "    plt.plot(self.history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train loss', 'val loss'],\n",
        "                loc='upper right')\n",
        "    plt.savefig(self.data_dir + \"results/\" + figureName + '.png')\n",
        "    plt.close()\n",
        "\n",
        "    if 'recon_loss' in self.history.history:\n",
        "        figureName = self.prefix + self.data + '_' + str(self.seed) + '_detailed'\n",
        "        plt.ylim(min(loss_collector) * 0.9, loss_max_atTheEnd * 2.0)\n",
        "        plt.plot(self.history.history['loss'])\n",
        "        plt.plot(self.history.history['val_loss'])\n",
        "        plt.plot(self.history.history['recon_loss'])\n",
        "        plt.plot(self.history.history['val_recon_loss'])\n",
        "        plt.plot(self.history.history['kl_loss'])\n",
        "        plt.plot(self.history.history['val_kl_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train loss', 'val loss', 'recon_loss', 'val recon_loss', 'kl_loss', 'val kl_loss'], loc='upper right')\n",
        "        plt.savefig(self.data_dir + \"results/\" + figureName + '.png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "  # supporting loss plot\n",
        "  def saveLossProgress_ylim(self):\n",
        "    loss_collector = []\n",
        "    loss_max_atTheEnd = 0.0\n",
        "    for hist in self.history.history:\n",
        "      current = self.history.history[hist]\n",
        "      loss_collector += current\n",
        "      if current[-1] >= loss_max_atTheEnd:\n",
        "        loss_max_atTheEnd = current[-1]\n",
        "    return loss_collector, loss_max_atTheEnd\n"
      ],
      "metadata": {
        "id": "5WDva6WosGE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Experiments"
      ],
      "metadata": {
        "id": "hY7oRbSRldrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main function for running an experiment\n",
        "def run_exp_from_config(config):\n",
        "  try:\n",
        "    if config.exp_design.repeat > 1:\n",
        "      for i in range(config.exp_design.repeat):\n",
        "        run_exp(i, config)\n",
        "    else:\n",
        "      run_exp(config.exp_design.seed, config)\n",
        "  except OSError as error:\n",
        "    print(error)\n",
        "\n",
        "def run_exp(seed, config):\n",
        "\n",
        "\n",
        "  # create an object and load data\n",
        "  ## no argument founded\n",
        "  if config.load_data.data == None and config.load_data.custom_data == None:\n",
        "    print(\"[Error] Please specify an input file. (use -h option for help)\")\n",
        "    exit()\n",
        "  ## provided data\n",
        "  elif config.load_data.data != None:\n",
        "    dm = DeepMicrobiome(data=config.load_data.data + '.txt', seed=seed, data_dir=config.load_data.data_dir)\n",
        "\n",
        "    ## specify feature string\n",
        "    feature_string = ''\n",
        "    data_string = str(config.load_data.data)\n",
        "    if data_string.split('_')[0] == 'abundance':\n",
        "      feature_string = \"k__\"\n",
        "    if data_string.split('_')[0] == 'marker':\n",
        "      feature_string = \"gi|\"\n",
        "\n",
        "    ## load data into the object\n",
        "    dm.loadData(feature_string=feature_string, label_string='disease', label_dict=label_dict,\n",
        "                dtype=dtypeDict[config.load_data.dataType])\n",
        "\n",
        "  ## user data\n",
        "  elif config.load_data.custom_data != None:\n",
        "    # PROBABLY NOT NECESSARY, I'VE COMMENTED IT OUT FOR NOW\n",
        "    \"\"\"\n",
        "    ### without labels - only conducting representation learning\n",
        "    if args.custom_data_labels == None:\n",
        "        dm = DeepMicrobiome(data=args.custom_data, seed=seed, data_dir=args.data_dir)\n",
        "        dm.loadCustomData(dtype=dtypeDict[args.dataType])\n",
        "\n",
        "    ### with labels - conducting representation learning + classification\n",
        "    else:\n",
        "        dm = DeepMicrobiome(data=args.custom_data, seed=seed, data_dir=args.data_dir)\n",
        "        dm.loadCustomDataWithLabels(label_data=args.custom_data_labels, dtype=dtypeDict[args.dataType])\n",
        "    \"\"\"\n",
        "    print(\"custom data currently unsupported.  TODO possibly if needed!\")\n",
        "  else:\n",
        "    exit()\n",
        "\n",
        "  numRLrequired = config.rl.pca + config.rl.ae + config.rl.rp + config.rl.vae + config.rl.cae\n",
        "\n",
        "  if numRLrequired > 1:\n",
        "    raise ValueError('No multiple dimensionality Reduction')\n",
        "\n",
        "  # time check after data has been loaded\n",
        "  dm.t_start = time.time()\n",
        "\n",
        "  # Representation learning (Dimensionality reduction)\n",
        "  if config.rl.pca:\n",
        "    dm.pca()\n",
        "  if config.rl.ae:\n",
        "    dm.ae(dims=[int(i) for i in config.common.dims.split(',')], act=config.common.act, epochs=config.common.max_epochs, loss=config.common.aeloss,\n",
        "          latent_act=config.AE.ae_lact, output_act=config.common.ae_oact, patience=config.common.patience, no_trn=config.others.no_trn)\n",
        "  if config.rl.vae:\n",
        "    dm.vae(dims=[int(i) for i in config.common.dims.split(',')], act=config.common.act, epochs=config.common.max_epochs, loss=config.common.aeloss, output_act=config.common.ae_oact,\n",
        "           patience= 25 if config.common.patience==20 else config.common.patience, beta=config.VAE.vae_beta, warmup=config.VAE.vae_warmup, warmup_rate=config.VAE.vae_warmup_rate, no_trn=config.others.no_trn)\n",
        "  if config.rl.cae:\n",
        "    dm.cae(dims=[int(i) for i in config.common.dims.split(',')], act=config.common.act, epochs=config.common.max_epochs, loss=config.common.aeloss, output_act=config.common.ae_oact,\n",
        "           patience=config.common.patience, rf_rate = config.CAE.rf_rate, st_rate = config.CAE.st_rate, no_trn=config.others.no_trn)\n",
        "  if config.rl.rp:\n",
        "    dm.rp()\n",
        "\n",
        "  # create saving path\n",
        "    if not os.path.exists(os.path.join(dm.data_dir, 'results')):\n",
        "      os.mkdir(os.path.join(dm.data_dir, 'results'))\n",
        "\n",
        "  # write the learned representation of the training set as a file\n",
        "  if config.rl.save_rep:\n",
        "    if numRLrequired == 1:\n",
        "      rep_file = dm.data_dir + \"results/\" + dm.prefix + dm.data + \"_rep.csv\"\n",
        "      pd.DataFrame(dm.X_train).to_csv(rep_file, header=None, index=None)\n",
        "      print(\"The learned representation of the training set has been saved in '{}'\".format(rep_file))\n",
        "    else:\n",
        "      print(\"Warning: Command option '--save_rep' is not applied as no representation learning or dimensionality reduction has been conducted.\")\n",
        "\n",
        "  # Classification\n",
        "  if config.others.no_clf or (config.load_data.data == None and config.load_data.custom_data_labels == None):\n",
        "    print(\"Classification task has been skipped.\")\n",
        "  else:\n",
        "    # turn off GPU\n",
        "    #\n",
        "    # NOTE FROM MATTHEW:  Can we port this over to pytorch?\n",
        "    #\n",
        "    #os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "    #importlib.reload(keras)\n",
        "\n",
        "    # training classification models\n",
        "    if config.classification.method == \"svm\":\n",
        "      dm.classification(hyper_parameters=svm_hyper_parameters, method='svm', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring, cache_size=config.classification.svm_cache)\n",
        "    elif config.classification.method == \"rf\":\n",
        "      dm.classification(hyper_parameters=rf_hyper_parameters, method='rf', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring)\n",
        "    elif config.classification.method == \"mlp\":\n",
        "      dm.classification(hyper_parameters=mlp_hyper_parameters, method='mlp', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring)\n",
        "    elif config.classification.method == \"svm_rf\":\n",
        "      dm.classification(hyper_parameters=svm_hyper_parameters, method='svm', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring, cache_size=config.classification.svm_cache)\n",
        "      dm.classification(hyper_parameters=rf_hyper_parameters, method='rf', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring)\n",
        "    else:\n",
        "      dm.classification(hyper_parameters=svm_hyper_parameters, method='svm', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring, cache_size=config.classification.svm_cache)\n",
        "      dm.classification(hyper_parameters=rf_hyper_parameters, method='rf', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring)\n",
        "      dm.classification(hyper_parameters=mlp_hyper_parameters, method='mlp', cv=config.classification.numFolds,\n",
        "                        n_jobs=config.classification.numJobs, scoring=config.classification.scoring)\n"
      ],
      "metadata": {
        "id": "jY5P3723sFjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Current Progress:**\n",
        "\n",
        "Successfully run model with ae, vae, pca, cae with auc results.\n",
        "\n",
        "**To-Do:**\n",
        "\n",
        "Show figures for each (By Apr 21)"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"config ae test\")\n",
        "config1 = DeepMicro_Config(\"ae_config\")\n",
        "run_exp_from_config(config1)\n"
      ],
      "metadata": {
        "id": "Y4WgUnso82d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f849f2bb-0e89-4638-9697-f8640acd813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config ae test\n",
            "loaded data from /content/drive/My Drive/Colab Notebooks/data/abundance/abundance_Cirrhosis.txt\n",
            "X_train.shape:  (185, 10)\n",
            "y_train.shape:  (185,)\n",
            "X_test.shape:  (47, 10)\n",
            "y_test.shape:  (47,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │             \u001b[38;5;34m550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m510\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,060\u001b[0m (4.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,060</span> (4.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,060\u001b[0m (4.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,060</span> (4.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.01602, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 1s - 680ms/step - loss: 0.0637 - val_loss: 0.0160\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_loss improved from 0.01602 to 0.01543, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 1s - 263ms/step - loss: 0.0612 - val_loss: 0.0154\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_loss improved from 0.01543 to 0.01488, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 28ms/step - loss: 0.0591 - val_loss: 0.0149\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_loss improved from 0.01488 to 0.01437, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0573 - val_loss: 0.0144\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_loss improved from 0.01437 to 0.01392, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0548 - val_loss: 0.0139\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_loss improved from 0.01392 to 0.01350, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0530 - val_loss: 0.0135\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: val_loss improved from 0.01350 to 0.01311, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 30ms/step - loss: 0.0509 - val_loss: 0.0131\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: val_loss improved from 0.01311 to 0.01274, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 31ms/step - loss: 0.0493 - val_loss: 0.0127\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: val_loss improved from 0.01274 to 0.01240, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 68ms/step - loss: 0.0475 - val_loss: 0.0124\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: val_loss improved from 0.01240 to 0.01207, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 27ms/step - loss: 0.0457 - val_loss: 0.0121\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: val_loss improved from 0.01207 to 0.01176, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 27ms/step - loss: 0.0442 - val_loss: 0.0118\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: val_loss improved from 0.01176 to 0.01144, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 30ms/step - loss: 0.0426 - val_loss: 0.0114\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: val_loss improved from 0.01144 to 0.01112, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 34ms/step - loss: 0.0408 - val_loss: 0.0111\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: val_loss improved from 0.01112 to 0.01081, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 66ms/step - loss: 0.0393 - val_loss: 0.0108\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: val_loss improved from 0.01081 to 0.01051, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 27ms/step - loss: 0.0384 - val_loss: 0.0105\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: val_loss improved from 0.01051 to 0.01022, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 28ms/step - loss: 0.0364 - val_loss: 0.0102\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: val_loss improved from 0.01022 to 0.00994, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0354 - val_loss: 0.0099\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: val_loss improved from 0.00994 to 0.00967, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0338 - val_loss: 0.0097\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: val_loss improved from 0.00967 to 0.00940, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 31ms/step - loss: 0.0323 - val_loss: 0.0094\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: val_loss improved from 0.00940 to 0.00914, saving model to AE_m_r_[50]_abundance_Cirrhosis.keras\n",
            "2/2 - 0s - 29ms/step - loss: 0.0313 - val_loss: 0.0091\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "The learned representation of the training set has been saved in '/content/drive/My Drive/Colab Notebooks/data/abundance/results/abundance_Cirrhosis_rep.csv'\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 1/5; 1/4] END ........C=0.25, kernel=linear;, score=0.649 total time=   0.0s\n",
            "[CV 2/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 2/5; 1/4] END ........C=0.25, kernel=linear;, score=0.683 total time=   0.0s\n",
            "[CV 3/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 3/5; 1/4] END ........C=0.25, kernel=linear;, score=0.646 total time=   0.0s\n",
            "[CV 4/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 4/5; 1/4] END ........C=0.25, kernel=linear;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 5/5; 1/4] END ........C=0.25, kernel=linear;, score=0.762 total time=   0.0s\n",
            "[CV 1/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 1/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.658 total time=   0.0s\n",
            "[CV 2/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 2/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 3/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.667 total time=   0.0s\n",
            "[CV 4/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 4/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 5/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.823 total time=   0.0s\n",
            "[CV 1/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 1/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.687 total time=   0.0s\n",
            "[CV 2/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 2/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.677 total time=   0.0s\n",
            "[CV 3/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 3/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.646 total time=   0.0s\n",
            "[CV 4/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 4/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 5/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 1/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.693 total time=   0.0s\n",
            "[CV 2/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 2/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.683 total time=   0.0s\n",
            "[CV 3/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 3/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.646 total time=   0.0s\n",
            "[CV 4/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 4/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 5/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.730 total time=   0.0s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 0.25, 'gamma': 0.5, 'kernel': 'rbf'}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.3388, 0.4894, 0.9583, 0.5, 0.6571, '2024-04-14 16:06:59.595107', 3.99, 0.22, \"{'C': 0.25, 'gamma': 0.5, 'kernel': 'rbf'}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.731 total time=   0.9s\n",
            "[CV 2/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.696 total time=   0.9s\n",
            "[CV 3/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.789 total time=   0.9s\n",
            "[CV 4/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.858 total time=   0.9s\n",
            "[CV 5/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   1.1s\n",
            "[CV 1/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.728 total time=   1.1s\n",
            "[CV 2/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.696 total time=   1.2s\n",
            "[CV 3/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.784 total time=   0.9s\n",
            "[CV 4/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.855 total time=   0.9s\n",
            "[CV 5/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   0.9s\n",
            "[CV 1/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.746 total time=   0.9s\n",
            "[CV 2/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.699 total time=   1.0s\n",
            "[CV 3/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   1.0s\n",
            "[CV 4/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.858 total time=   0.9s\n",
            "[CV 5/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   0.9s\n",
            "[CV 1/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.760 total time=   0.9s\n",
            "[CV 2/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.699 total time=   0.9s\n",
            "[CV 3/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   1.0s\n",
            "[CV 4/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.855 total time=   1.1s\n",
            "[CV 5/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.781 total time=   1.1s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2, 'n_estimators': 500}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.6667, 0.6383, 0.625, 0.6522, 0.6383, '2024-04-14 16:07:20.418078', 24.81, 20.82, \"{'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2, 'n_estimators': 500}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "mlp classifier todo\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV 1/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7825cf94a8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.749 total time=   8.1s\n",
            "[CV 2/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7825cf94a830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.827 total time=  13.4s\n",
            "[CV 3/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.599 total time=   8.3s\n",
            "[CV 4/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.392 total time=   8.4s\n",
            "[CV 5/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.702 total time=   7.5s\n",
            "[CV 1/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.579 total time=   8.9s\n",
            "[CV 2/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.857 total time=   8.4s\n",
            "[CV 3/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.696 total time=   9.3s\n",
            "[CV 4/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.623 total time=   8.5s\n",
            "[CV 5/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.681 total time=  12.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'dropout_rate': 0.3, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.587, 0.5106, 0.9583, 0.5111, 0.6667, '2024-04-14 16:09:03.687317', 128.08, 103.26, \"{'dropout_rate': 0.3, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"config cae test\")\n",
        "config2 = DeepMicro_Config(\"cae_config\")\n",
        "run_exp_from_config(config2)"
      ],
      "metadata": {
        "id": "2sMiKPrrArc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55034328-6aa4-4f71-bd46-4c2127b7e73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config cae test\n",
            "loaded data from /content/drive/My Drive/Colab Notebooks/data/abundance/abundance_Cirrhosis.txt\n",
            "X_train.shape:  (185, 10)\n",
            "y_train.shape:  (185,)\n",
            "X_test.shape:  (47, 10)\n",
            "y_test.shape:  (47,)\n",
            "X_train.shape:  (185, 4, 4, 1)\n",
            "y_train.shape:  (185,)\n",
            "X_test.shape:  (47, 4, 4, 1)\n",
            "y_test.shape:  (47,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_78\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_78\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │             \u001b[38;5;34m500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m22,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m40,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m22,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m451\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">451</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,251\u001b[0m (336.92 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,251</span> (336.92 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,251\u001b[0m (336.92 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,251</span> (336.92 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.01256, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 7s - 4s/step - loss: 0.0576 - val_loss: 0.0126\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_loss improved from 0.01256 to 0.01207, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 5s - 2s/step - loss: 0.0558 - val_loss: 0.0121\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_loss improved from 0.01207 to 0.01145, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 70ms/step - loss: 0.0523 - val_loss: 0.0114\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_loss improved from 0.01145 to 0.01073, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 48ms/step - loss: 0.0482 - val_loss: 0.0107\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_loss improved from 0.01073 to 0.00986, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 68ms/step - loss: 0.0444 - val_loss: 0.0099\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_loss improved from 0.00986 to 0.00892, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 67ms/step - loss: 0.0406 - val_loss: 0.0089\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: val_loss improved from 0.00892 to 0.00782, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 69ms/step - loss: 0.0333 - val_loss: 0.0078\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: val_loss improved from 0.00782 to 0.00655, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 76ms/step - loss: 0.0240 - val_loss: 0.0065\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: val_loss improved from 0.00655 to 0.00523, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 64ms/step - loss: 0.0156 - val_loss: 0.0052\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: val_loss improved from 0.00523 to 0.00423, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 47ms/step - loss: 0.0089 - val_loss: 0.0042\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: val_loss improved from 0.00423 to 0.00402, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 48ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.00402\n",
            "2/2 - 0s - 51ms/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: val_loss improved from 0.00402 to 0.00395, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 65ms/step - loss: 0.0045 - val_loss: 0.0039\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: val_loss improved from 0.00395 to 0.00380, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 49ms/step - loss: 0.0029 - val_loss: 0.0038\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.00380\n",
            "2/2 - 0s - 23ms/step - loss: 0.0012 - val_loss: 0.0041\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.00380\n",
            "2/2 - 0s - 27ms/step - loss: 0.0014 - val_loss: 0.0044\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.00380\n",
            "2/2 - 0s - 26ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.00380\n",
            "2/2 - 0s - 29ms/step - loss: 0.0024 - val_loss: 0.0041\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: val_loss improved from 0.00380 to 0.00378, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 47ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: val_loss improved from 0.00378 to 0.00356, saving model to /content/drive/My Drive/Colab Notebooks/data/abundance/CAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 68ms/step - loss: 8.9902e-04 - val_loss: 0.0036\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
            "X_train.shape:  (185, 200)\n",
            "y_train.shape:  (185,)\n",
            "X_test.shape:  (47, 200)\n",
            "y_test.shape:  (47,)\n",
            "The learned representation of the training set has been saved in '/content/drive/My Drive/Colab Notebooks/data/abundance/results/CAE[50]_abundance_Cirrhosis_rep.csv'\n",
            "# Tuning hyper-parameters\n",
            "(185, 200) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 1/5; 1/4] END ........C=0.25, kernel=linear;, score=0.863 total time=   0.0s\n",
            "[CV 2/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 2/5; 1/4] END ........C=0.25, kernel=linear;, score=0.670 total time=   0.0s\n",
            "[CV 3/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 3/5; 1/4] END ........C=0.25, kernel=linear;, score=0.693 total time=   0.0s\n",
            "[CV 4/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 4/5; 1/4] END ........C=0.25, kernel=linear;, score=0.655 total time=   0.0s\n",
            "[CV 5/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 5/5; 1/4] END ........C=0.25, kernel=linear;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 1/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.822 total time=   0.0s\n",
            "[CV 2/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 2/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.643 total time=   0.0s\n",
            "[CV 3/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 3/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.649 total time=   0.0s\n",
            "[CV 4/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 4/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.678 total time=   0.0s\n",
            "[CV 5/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 5/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 1/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 2/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 3/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.646 total time=   0.0s\n",
            "[CV 4/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 4/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.655 total time=   0.0s\n",
            "[CV 5/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 5/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.778 total time=   0.0s\n",
            "[CV 1/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 1/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 2/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.658 total time=   0.0s\n",
            "[CV 3/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 3/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.649 total time=   0.0s\n",
            "[CV 4/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 4/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.658 total time=   0.0s\n",
            "[CV 5/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 5/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.816 total time=   0.0s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 0.25, 'kernel': 'linear'}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.6703, 0.4894, 0.9583, 0.5, 0.6571, '2024-04-14 16:18:17.466565', 16.75, 0.49, \"{'C': 0.25, 'kernel': 'linear'}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 200) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.792 total time=   1.2s\n",
            "[CV 2/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.737 total time=   0.9s\n",
            "[CV 3/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.708 total time=   0.9s\n",
            "[CV 4/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.737 total time=   0.9s\n",
            "[CV 5/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.731 total time=   0.9s\n",
            "[CV 1/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.792 total time=   0.9s\n",
            "[CV 2/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.731 total time=   0.9s\n",
            "[CV 3/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.696 total time=   0.9s\n",
            "[CV 4/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.743 total time=   0.9s\n",
            "[CV 5/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.743 total time=   0.9s\n",
            "[CV 1/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.798 total time=   0.9s\n",
            "[CV 2/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.719 total time=   1.1s\n",
            "[CV 3/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.716 total time=   1.2s\n",
            "[CV 4/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.746 total time=   1.3s\n",
            "[CV 5/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.743 total time=   1.0s\n",
            "[CV 1/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.801 total time=   0.9s\n",
            "[CV 2/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.719 total time=   0.9s\n",
            "[CV 3/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.705 total time=   1.0s\n",
            "[CV 4/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.740 total time=   0.9s\n",
            "[CV 5/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.740 total time=   0.9s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.6413, 0.617, 0.625, 0.625, 0.625, '2024-04-14 16:18:38.417253', 37.7, 20.94, \"{'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 200) (185,)\n",
            "mlp classifier todo\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV 1/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.618 total time=   9.0s\n",
            "[CV 2/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.678 total time=   7.7s\n",
            "[CV 3/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.617 total time=   8.3s\n",
            "[CV 4/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.825 total time=   9.2s\n",
            "[CV 5/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.675 total time=  12.5s\n",
            "[CV 1/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.621 total time=   8.6s\n",
            "[CV 2/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.731 total time=   8.9s\n",
            "[CV 3/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.775 total time=   8.7s\n",
            "[CV 4/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.667 total time=   8.4s\n",
            "[CV 5/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.635 total time=  13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'dropout_rate': 0.3, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.6757, 0.5106, 0.9167, 0.5116, 0.6567, '2024-04-14 16:20:21.959959', 141.24, 103.53, \"{'dropout_rate': 0.3, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"config vae test\")\n",
        "config3 = DeepMicro_Config(\"vae_config\")\n",
        "run_exp_from_config(config3)"
      ],
      "metadata": {
        "id": "LjW9bCkouv8O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d2af183-ccaf-4baf-9125-7053cf013ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config vae test\n",
            "loaded data from /content/drive/My Drive/Colab Notebooks/data/abundance/abundance_Cirrhosis.txt\n",
            "X_train.shape:  (185, 10)\n",
            "y_train.shape:  (185,)\n",
            "X_test.shape:  (47, 10)\n",
            "y_test.shape:  (47,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"vae\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)                 │ ?                           │           \u001b[38;5;34m1,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)                 │ ?                           │             \u001b[38;5;34m510\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                 │ ?                           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                 │ ?                           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,610\u001b[0m (6.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,610</span> (6.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,610\u001b[0m (6.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,610</span> (6.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │            \u001b[38;5;34m550\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │            \u001b[38;5;34m550\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z (\u001b[38;5;33mLambda\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,100\u001b[0m (4.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> (4.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,100\u001b[0m (4.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> (4.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m510\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m510\u001b[0m (1.99 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> (1.99 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m510\u001b[0m (1.99 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> (1.99 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 17.59176, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 1s - 721ms/step - loss: 0.0000e+00 - val_loss: 17.5918\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_loss improved from 17.59176 to 15.96755, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 38ms/step - loss: 0.0000e+00 - val_loss: 15.9676\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_loss improved from 15.96755 to 15.73457, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 40ms/step - loss: 0.0000e+00 - val_loss: 15.7346\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_loss improved from 15.73457 to 14.25566, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 37ms/step - loss: 0.0000e+00 - val_loss: 14.2557\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_loss improved from 14.25566 to 13.95582, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 69ms/step - loss: 0.0000e+00 - val_loss: 13.9558\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_loss did not improve from 13.95582\n",
            "2/2 - 0s - 26ms/step - loss: 0.0000e+00 - val_loss: 14.9420\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: val_loss did not improve from 13.95582\n",
            "2/2 - 0s - 29ms/step - loss: 0.0000e+00 - val_loss: 16.7960\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: val_loss did not improve from 13.95582\n",
            "2/2 - 0s - 29ms/step - loss: 0.0000e+00 - val_loss: 15.0944\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: val_loss did not improve from 13.95582\n",
            "2/2 - 0s - 28ms/step - loss: 0.0000e+00 - val_loss: 15.2060\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: val_loss did not improve from 13.95582\n",
            "2/2 - 0s - 25ms/step - loss: 0.0000e+00 - val_loss: 14.2093\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: val_loss improved from 13.95582 to 13.47877, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 54ms/step - loss: 0.0000e+00 - val_loss: 13.4788\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: val_loss did not improve from 13.47877\n",
            "2/2 - 0s - 123ms/step - loss: 0.0000e+00 - val_loss: 14.4229\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: val_loss improved from 13.47877 to 13.33851, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 142ms/step - loss: 0.0000e+00 - val_loss: 13.3385\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: val_loss improved from 13.33851 to 12.71805, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 127ms/step - loss: 0.0000e+00 - val_loss: 12.7180\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: val_loss did not improve from 12.71805\n",
            "2/2 - 0s - 41ms/step - loss: 0.0000e+00 - val_loss: 14.3934\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: val_loss did not improve from 12.71805\n",
            "2/2 - 0s - 55ms/step - loss: 0.0000e+00 - val_loss: 13.9586\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: val_loss improved from 12.71805 to 11.42570, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 59ms/step - loss: 0.0000e+00 - val_loss: 11.4257\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: val_loss did not improve from 11.42570\n",
            "2/2 - 0s - 46ms/step - loss: 0.0000e+00 - val_loss: 12.1597\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: val_loss did not improve from 11.42570\n",
            "2/2 - 0s - 76ms/step - loss: 0.0000e+00 - val_loss: 13.0608\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: val_loss improved from 11.42570 to 10.22863, saving model to VAE[50]_abundance_Cirrhosis.weights.h5\n",
            "2/2 - 0s - 178ms/step - loss: 0.0000e+00 - val_loss: 10.2286\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "The learned representation of the training set has been saved in '/content/drive/My Drive/Colab Notebooks/data/abundance/results/VAE[50]_abundance_Cirrhosis_rep.csv'\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 1/5; 1/4] END ........C=0.25, kernel=linear;, score=0.231 total time=   0.1s\n",
            "[CV 2/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 2/5; 1/4] END ........C=0.25, kernel=linear;, score=0.380 total time=   0.0s\n",
            "[CV 3/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 3/5; 1/4] END ........C=0.25, kernel=linear;, score=0.430 total time=   0.1s\n",
            "[CV 4/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 4/5; 1/4] END ........C=0.25, kernel=linear;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 1/4] START C=0.25, kernel=linear.......................................\n",
            "[CV 5/5; 1/4] END ........C=0.25, kernel=linear;, score=0.605 total time=   0.0s\n",
            "[CV 1/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 1/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 2/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 3/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 4/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.500 total time=   0.1s\n",
            "[CV 5/5; 2/4] START C=0.25, gamma=2, kernel=rbf.................................\n",
            "[CV 5/5; 2/4] END ..C=0.25, gamma=2, kernel=rbf;, score=0.500 total time=   0.0s\n",
            "[CV 1/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 1/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.477 total time=   0.0s\n",
            "[CV 2/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 2/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 3/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.436 total time=   0.0s\n",
            "[CV 4/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 4/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.503 total time=   0.0s\n",
            "[CV 5/5; 3/4] START C=0.25, gamma=0.5, kernel=rbf...............................\n",
            "[CV 5/5; 3/4] END C=0.25, gamma=0.5, kernel=rbf;, score=0.430 total time=   0.0s\n",
            "[CV 1/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 1/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.363 total time=   0.0s\n",
            "[CV 2/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 2/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.550 total time=   0.0s\n",
            "[CV 3/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 3/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.339 total time=   0.0s\n",
            "[CV 4/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 4/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 4/4] START C=0.25, gamma=0.125, kernel=rbf.............................\n",
            "[CV 5/5; 4/4] END C=0.25, gamma=0.125, kernel=rbf;, score=0.444 total time=   0.0s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 0.25, 'gamma': 2, 'kernel': 'rbf'}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.5, 0.5106, 1.0, 0.5106, 0.6761, '2024-04-14 17:30:14.354633', 6.58, 0.83, \"{'C': 0.25, 'gamma': 2, 'kernel': 'rbf'}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.398 total time=   2.7s\n",
            "[CV 2/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.541 total time=   3.1s\n",
            "[CV 3/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.488 total time=   2.0s\n",
            "[CV 4/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.406 total time=   1.9s\n",
            "[CV 5/5; 1/4] START criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 1/4] END criterion=gini, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.491 total time=   1.8s\n",
            "[CV 1/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.412 total time=   1.8s\n",
            "[CV 2/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.599 total time=   1.9s\n",
            "[CV 3/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.491 total time=   3.5s\n",
            "[CV 4/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.401 total time=   2.9s\n",
            "[CV 5/5; 2/4] START criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 2/4] END criterion=gini, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.459 total time=   1.8s\n",
            "[CV 1/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.462 total time=   2.3s\n",
            "[CV 2/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.558 total time=   2.4s\n",
            "[CV 3/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.556 total time=   2.3s\n",
            "[CV 4/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.409 total time=   3.4s\n",
            "[CV 5/5; 3/4] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 3/4] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, n_estimators=500;, score=0.439 total time=   2.6s\n",
            "[CV 1/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 1/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.418 total time=   2.5s\n",
            "[CV 2/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 2/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.573 total time=   1.8s\n",
            "[CV 3/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 3/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.480 total time=   2.0s\n",
            "[CV 4/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 4/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.421 total time=   3.0s\n",
            "[CV 5/5; 4/4] START criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500\n",
            "[CV 5/5; 4/4] END criterion=entropy, max_features=log2, min_samples_leaf=2, n_estimators=500;, score=0.482 total time=   2.6s\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.5109, 0.4681, 0.5833, 0.4828, 0.5283, '2024-04-14 17:31:05.611208', 57.83, 50.99, \"{'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\"]\n",
            "# Tuning hyper-parameters\n",
            "(185, 50) (185,)\n",
            "mlp classifier todo\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV 1/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.395 total time=   4.0s\n",
            "[CV 2/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e0d64298b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e0d64298b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.687 total time=   6.0s\n",
            "[CV 3/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n",
            "[CV 3/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.500 total time=   4.9s\n",
            "[CV 4/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.478 total time=   2.8s\n",
            "[CV 5/5; 1/2] START dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/2] END dropout_rate=0.1, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.601 total time=   2.8s\n",
            "[CV 1/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.430 total time=   3.1s\n",
            "[CV 2/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.272 total time=   3.0s\n",
            "[CV 3/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.523 total time=   2.7s\n",
            "[CV 4/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.500 total time=   2.7s\n",
            "[CV 5/5; 2/2] START dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/2] END dropout_rate=0.3, epochs=30, numHiddenLayers=2, numUnits=10;, score=0.506 total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'dropout_rate': 0.1, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\n",
            "Accuracy metrics\n",
            "AUC, ACC, Recall, Precision, F1_score, time-end, runtime(sec), classfication time(sec), best hyper-parameter\n",
            "[0.5362, 0.5319, 0.375, 0.5625, 0.45, '2024-04-14 17:31:44.096194', 96.32, 38.47, \"{'dropout_rate': 0.1, 'epochs': 30, 'numHiddenLayers': 2, 'numUnits': 10}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test a full (simple) workflow with PCA and SVM\n",
        "print(\"\\nconfig 1 test\")\n",
        "config1 = DeepMicro_Config(\"test_experiment_config_1\")\n",
        "run_exp_from_config(config1)\n",
        "\n",
        "# Note: You don't have to create a whole new config file when you're just changing one or two parameters.\n",
        "# you can run a slightly modified experiment like this (e.g. here we're using the same exeriment on a different dataset):\n",
        "# Test config of no autoencoder\n",
        "config1_using_marker_colorectal = config1\n",
        "config1_using_marker_colorectal.load_data.data_dir = \"/content/drive/My Drive/Colab Notebooks/data/marker/\"\n",
        "config1_using_marker_colorectal.load_data.data = \"marker_Colorectal\"\n",
        "run_exp_from_config(config1_using_marker_colorectal)"
      ],
      "metadata": {
        "id": "OvIFEMdHm8Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To-Do:**\n",
        "\n",
        "Train model in full epoches and compare results. (By Apr 28)\n",
        "- we can compare the results of the different models in terms of accuracy, AUC, etc. And,\n",
        "- the time taken to train each model\n",
        "- the best hyperparameters found for each model"
      ],
      "metadata": {
        "id": "n_30uovDnQxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n",
        "---\n",
        "\n",
        "**To-Do:**\n",
        "\n",
        "Add discussion. (By Apr 28)\n",
        "\n",
        "- discuss the reproducibility of the paper and the ease of reproducing the results.\n",
        "- discuss what was easy and what was difficult during the reproduction.\n",
        "- make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "- discuss the results of the model comparison and the implications of the results.\n",
        "- discuss the limitations of the study and the potential future work.\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Cho, I., & Blaser, M. J. (2012). The human microbiome: at the interface of health and disease. Nature Reviews Genetics, 13(4), 260-270.\n",
        "2. Huttenhower, C. et al. Structure, function and diversity of the healthy human microbiome. nature 486, 207 (2012).\n",
        "3. McQuade, J. L., Daniel, C. R., Helmink, B. A. & Wargo, J. A. Modulating the microbiome to improve therapeutic response in cancer. The Lancet Oncology 20, e77–e91 (2019).\n",
        "4. Eloe-Fadrosh, E. A. & Rasko, D. A. The human microbiome: from symbiosis to pathogenesis. Annual review of medicine 64, 145–163 (2013).\n",
        "5. Scholz, M. et al. Strain-level microbial epidemiology and population genomics from shotgun metagenomics. Nature methods 13, 435 (2016).\n",
        "6. Truong, D. T. et al. MetaPhlAn2 for enhanced metagenomic taxonomic profiling. Nature methods 12, 902 (2015).\n",
        "7. Oh, M., & Zhang, L. (2020). DeepMicro: deep representation learning for disease prediction based on microbiome data. Scientific reports, 10(1), 6026.\n",
        "8. Pasolli, E., Truong, D. T., Malik, F., Waldron, L. & Segata, N. Machine learning meta-analysis of large metagenomic datasets: tools and biological insights. PLoS computational biology 12, e1004977 (2016).\n",
        "9. Cawley, G. C. & Talbot, N. L. On over-fitting in model selection and subsequent selection bias in performance evaluation. Journal of Machine Learning Research 11, 2079–2107 (2010).\n",
        "10. Varma, S. & Simon, R. Bias in error estimation when using cross-validation for model selection. BMC bioinformatics 7, 91 (2006).\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}